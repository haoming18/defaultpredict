{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57fd44e7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.003686,
     "end_time": "2022-07-08T16:22:32.600665",
     "exception": false,
     "start_time": "2022-07-08T16:22:32.596979",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Comments:\n",
    "    \n",
    "This is an improvement of my baseline, you can find it here: https://www.kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7963\n",
    "\n",
    "The main difference between this solution and previous one is that we add new features and do seed blend to boost LB. Single 5 kfold model using seed 42 achieve an out of folds CV of 0.7977 and a public leaderboard of 0.799. If we use seed blend (train three different models using seed 42, 52, 62 and then average predictions) the LB boost niceley.\n",
    "\n",
    "The main features that boost CV are the following:\n",
    "\n",
    "* The difference between last value and the lag1\n",
    "* The difference between last value and the average (this features gives a nice boost)\n",
    "\n",
    "This feature engineer is done on all the last columns, so we actually add a lot of features, this model used 1368 features.\n",
    "\n",
    "I uploaded test predictions to avoid running training and inference\n",
    "\n",
    "Next Steps:\n",
    "\n",
    "* Could try feature selection, maybe a lot of the feature are just noise, actually I perform permutation importance and I reduce the amount of features to 1000 app and the CV was almost the same. Maybe there is a better feature selection technique that can boost performance.\n",
    "\n",
    "* Could try different models, maybe some neural network with the same features or a subset of the features and then blend with LGBM can work, in my experience blending tree models and neural network works great because they are very diverse so the boost is nice\n",
    "\n",
    "* Could try more feature engineering, maybe we can create more features that extract the hidden signal of the dataset, actually I would first work on this option and really try to capture all the signal that the dataset has."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2991d5a9",
   "metadata": {
    "papermill": {
     "duration": 0.002483,
     "end_time": "2022-07-08T16:22:32.606139",
     "exception": false,
     "start_time": "2022-07-08T16:22:32.603656",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e463318",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T16:22:32.613941Z",
     "iopub.status.busy": "2022-07-08T16:22:32.612882Z",
     "iopub.status.idle": "2022-07-08T16:22:32.784248Z",
     "shell.execute_reply": "2022-07-08T16:22:32.783021Z"
    },
    "papermill": {
     "duration": 0.17854,
     "end_time": "2022-07-08T16:22:32.787260",
     "exception": false,
     "start_time": "2022-07-08T16:22:32.608720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import joblib\n",
    "import random\n",
    "import warnings\n",
    "import itertools\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from itertools import combinations\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "def get_difference(data, num_features):\n",
    "    df1,df3,df6 = [],[],[]\n",
    "    customer_ids = []\n",
    "    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n",
    "        diff_df1 = df[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n",
    "        diff_df3 = df[num_features].diff(3).iloc[[-1]].values.astype(np.float32)\n",
    "        diff_df6 = df[num_features].diff(6).iloc[[-1]].values.astype(np.float32)\n",
    "\n",
    "        df1.append(diff_df1)\n",
    "        df3.append(diff_df3)\n",
    "        df6.append(diff_df6)\n",
    "        customer_ids.append(customer_id)\n",
    "        \n",
    "    df1 = np.concatenate(df1, axis = 0)\n",
    "    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n",
    "    df3 = np.concatenate(df3, axis = 0)\n",
    "    df3 = pd.DataFrame(df3, columns = [col + '_diff3' for col in df[num_features].columns])\n",
    "    df6 = np.concatenate(df6, axis = 0)\n",
    "    df6 = pd.DataFrame(df6, columns = [col + '_diff6' for col in df[num_features].columns])\n",
    "    df_all = pd.concat([df1,df3,df6],axis=1)\n",
    "    df_all['customer_ID'] = customer_ids\n",
    "    return df_all\n",
    "\n",
    "def read_preprocess_data():\n",
    "    train = pd.read_parquet('../input/amex-data-integer-dtypes-parquet-format/train.parquet')\n",
    "    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\",\n",
    "    ]\n",
    "    num_features = [col for col in features if col not in cat_features]\n",
    "    print('Starting training feature engineer...')\n",
    "    train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max'])\n",
    "    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
    "    train_num_agg.reset_index(inplace = True)\n",
    "    \n",
    "    train_tail2 = train.groupby(\"customer_ID\").tail(2)\n",
    "    train_tail2_num_agg = train_tail2.groupby(\"customer_ID\")[num_features].agg(['mean'])\n",
    "    train_tail2_num_agg.columns = ['_'.join([xx.replace('mean','last') for xx in x]) for x in train_tail2_num_agg.columns]\n",
    "    train_tail2_num_agg.reset_index(inplace = True)\n",
    "\n",
    "    train_num_agg = train_num_agg.merge(train_tail2_num_agg, how = 'inner', on = 'customer_ID')\n",
    "    # Lag Features\n",
    "    for col in num_features:\n",
    "        train_num_agg[f'{col}_last_mean_diff'] = train_num_agg[f'{col}_last'] - train_num_agg[f'{col}_mean']\n",
    "        train_num_agg[f'{col}_last_first_diff'] = train_num_agg[f'{col}_last'] - train_num_agg[f'{col}_first']\n",
    "\n",
    "    train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['count', 'first', 'last', 'nunique'])\n",
    "    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
    "    train_cat_agg.reset_index(inplace = True)\n",
    "    train_labels = pd.read_csv('../input/amex-default-prediction/train_labels.csv')\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(train_num_agg.dtypes[train_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_num_agg[col] = train_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(train_cat_agg.dtypes[train_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_cat_agg[col] = train_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    train_diff = get_difference(train, num_features)\n",
    "    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').\\\n",
    "            merge(train_diff, how = 'inner', on = 'customer_ID').\\\n",
    "            merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "    del train_num_agg, train_cat_agg, train_diff, train_tail2_num_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    test = pd.read_parquet('../input/amex-data-integer-dtypes-parquet-format/test.parquet')\n",
    "    print('Starting test feature engineer...')\n",
    "    test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "    test_num_agg.reset_index(inplace = True)\n",
    "\n",
    "    \n",
    "    test_tail2 = test.groupby(\"customer_ID\").tail(2)\n",
    "    test_tail2_num_agg = test_tail2.groupby(\"customer_ID\")[num_features].agg(['mean'])\n",
    "    test_tail2_num_agg.columns = ['_'.join([xx.replace('mean','last') for xx in x]) for x in test_tail2_num_agg.columns]\n",
    "    test_tail2_num_agg.reset_index(inplace = True)\n",
    "\n",
    "    test_num_agg = test_num_agg.merge(test_tail2_num_agg, how = 'inner', on = 'customer_ID')\n",
    "\n",
    "    # Lag Features\n",
    "    for col in num_features:\n",
    "        test_num_agg[f'{col}_last_mean_diff'] = test_num_agg[f'{col}_last'] - test_num_agg[f'{col}_mean']\n",
    "        test_num_agg[f'{col}_last_first_diff'] = test_num_agg[f'{col}_last'] - test_num_agg[f'{col}_first']\n",
    "\n",
    "\n",
    "    test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['count', 'first', 'last', 'nunique'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "    test_cat_agg.reset_index(inplace = True)\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(test_num_agg.dtypes[test_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_num_agg[col] = test_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(test_cat_agg.dtypes[test_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_cat_agg[col] = test_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    test_diff = get_difference(test, num_features)\n",
    "    test = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID').\\\n",
    "            merge(test_diff, how = 'inner', on = 'customer_ID')\n",
    "    del test_num_agg, test_cat_agg, test_diff\n",
    "    gc.collect()\n",
    "\n",
    "    features = train.drop(['customer_ID'], axis = 1).columns.to_list()\n",
    "    num_features = [col for col in features if col not in cat_features]\n",
    "    num_cols = [col for col in num_features if (('last' in col or 'mean' in col) and 'diff' not in col)]\n",
    "    for col in num_cols:\n",
    "        train[col + '_round2'] = train[col].round(2)\n",
    "        test[col + '_round2'] = test[col].round(2)\n",
    "    \n",
    "    print('train.shape:',train.shape)\n",
    "    print('test.shape:',test.shape)\n",
    "\n",
    "    # Save files to disk\n",
    "    train.to_parquet('train_fe.parquet')\n",
    "    test.to_parquet('test_fe.parquet')\n",
    "    \n",
    "# Read & Preprocess Data\n",
    "# read_preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8971190e",
   "metadata": {
    "papermill": {
     "duration": 0.002484,
     "end_time": "2022-07-08T16:22:32.792603",
     "exception": false,
     "start_time": "2022-07-08T16:22:32.790119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc68eb15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T16:22:32.800423Z",
     "iopub.status.busy": "2022-07-08T16:22:32.800064Z",
     "iopub.status.idle": "2022-07-08T16:22:34.760230Z",
     "shell.execute_reply": "2022-07-08T16:22:34.759213Z"
    },
    "papermill": {
     "duration": 1.967553,
     "end_time": "2022-07-08T16:22:34.762846",
     "exception": false,
     "start_time": "2022-07-08T16:22:32.795293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import itertools\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from itertools import combinations\n",
    "from catboost import CatBoostClassifier\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    input_dir = './'\n",
    "    seed = 42\n",
    "    n_folds = 5\n",
    "    target = 'target'\n",
    "    boosting_type = 'dart'\n",
    "    metric = 'binary_logloss'\n",
    "\n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "def read_data():\n",
    "    train = pd.read_parquet(CFG.input_dir + 'train_fe_v2.parquet')\n",
    "    test = pd.read_parquet(CFG.input_dir + 'train_fe_v2.parquet')\n",
    "    return train, test\n",
    "\n",
    "# ====================================================\n",
    "# Amex metric\n",
    "# ====================================================\n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "# ====================================================\n",
    "# LGBM amex metric\n",
    "# ====================================================\n",
    "def lgb_amex_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'amex_metric', amex_metric(y_true, y_pred), True\n",
    "\n",
    "# ====================================================\n",
    "# Train & Evaluate\n",
    "# ====================================================\n",
    "def train_and_evaluate(train, test):\n",
    "    # Label encode categorical features\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\"\n",
    "    ]\n",
    "    cat_features = [f\"{cf}_last\" for cf in cat_features] +  [f\"{cf}_first\" for cf in cat_features]\n",
    "    for cat_col in cat_features:\n",
    "        encoder = LabelEncoder()\n",
    "        train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "        test[cat_col] = encoder.transform(test[cat_col])\n",
    "#     # Round last float features to 2 decimal place\n",
    "#     num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "#     num_cols = [col for col in num_cols if 'last' in col]\n",
    "#     for col in num_cols:\n",
    "#         train[col + '_round2'] = train[col].round(2)\n",
    "#         test[col + '_round2'] = test[col].round(2)\n",
    "#     # Get the difference between last and mean\n",
    "#     num_cols = [col for col in train.columns if 'last' in col]\n",
    "#     num_cols = [col[:-5] for col in num_cols if 'round' not in col]\n",
    "#     for col in num_cols:\n",
    "#         try:\n",
    "#             train[f'{col}_last_mean_diff'] = train[f'{col}_last'] - train[f'{col}_mean']\n",
    "#             test[f'{col}_last_mean_diff'] = test[f'{col}_last'] - test[f'{col}_mean']\n",
    "#         except:\n",
    "#             pass\n",
    "    # Transform float64 and float32 to float16\n",
    "    num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "#     for col in tqdm(num_cols):\n",
    "#         train[col] = train[col].astype(np.float16)\n",
    "#         test[col] = test[col].astype(np.float16)\n",
    "    # Get feature list\n",
    "    features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "    features = [col for col in features if 'B_29' not in col]\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': CFG.metric,\n",
    "        'boosting': CFG.boosting_type,\n",
    "        'seed': CFG.seed,\n",
    "        'num_leaves': 100,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.20,\n",
    "        'bagging_freq': 10,\n",
    "        'bagging_fraction': 0.50,\n",
    "        'n_jobs': -1,\n",
    "        'lambda_l2': 2,\n",
    "        'min_data_in_leaf': 40,\n",
    "        }\n",
    "    # Create a numpy array to store test predictions\n",
    "    test_predictions = np.zeros(len(test))\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    oof_predictions = np.zeros(len(train))\n",
    "    kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "        print(' ')\n",
    "        print('-'*50)\n",
    "        print(f'Training fold {fold} with {len(features)} features...')\n",
    "        x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "        y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "        model = CatBoostClassifier(iterations=10000,learning_rate=0.03, random_state=22,task_type='GPU')\n",
    "        model.fit(x_train, y_train, eval_set=[(x_val, y_val)], cat_features=cat_features,  verbose=100, use_best_model=True)\n",
    "        joblib.dump(model, f'cat_fold{fold}_seed{CFG.seed}.pkl')\n",
    "        val_pred = model.predict_proba(x_val)[:, 1]\n",
    "\n",
    "#         lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
    "#         lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
    "#         model = lgb.train(\n",
    "#             params = params,\n",
    "#             train_set = lgb_train,\n",
    "#             num_boost_round = 10500,\n",
    "#             valid_sets = [lgb_train, lgb_valid],\n",
    "#             early_stopping_rounds = 1500,\n",
    "#             verbose_eval = 500,\n",
    "#             feval = lgb_amex_metric\n",
    "#             )\n",
    "#         # Save best model\n",
    "#         joblib.dump(model, f'/content/drive/MyDrive/Amex/Models/lgbm_{CFG.boosting_type}_fold{fold}_seed{CFG.seed}.pkl')\n",
    "        # Predict validation\n",
    "#         val_pred = model.predict(x_val)\n",
    "        # Add to out of folds array\n",
    "        oof_predictions[val_ind] = val_pred\n",
    "        # Predict the test set\n",
    "        test_pred_list = []\n",
    "        for ii in tqdm(range(int(len(test)/10000)+1)):\n",
    "            test_pred_tmp = model.predict_proba(test[ii*10000:(ii+1)*10000][features])[:, 1]\n",
    "            test_pred_list.append(test_pred_tmp)\n",
    "        test_pred = np.concatenate(test_pred_list)\n",
    "#         test_pred = model.predict(test[features])\n",
    "        test_predictions += test_pred / CFG.n_folds\n",
    "        # Compute fold metric\n",
    "        score = amex_metric(y_val, val_pred)\n",
    "        print(f'Our fold {fold} CV score is {score}')\n",
    "        del x_train, x_val, y_train, y_val\n",
    "        gc.collect()\n",
    "    # Compute out of folds metric\n",
    "    score = amex_metric(train[CFG.target], oof_predictions)\n",
    "    print(f'Our out of folds CV score is {score}')\n",
    "    # Create a dataframe to store out of folds predictions\n",
    "    oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "    oof_df.to_csv(f'oof_cat_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "    # Create a dataframe to store test prediction\n",
    "    test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "    test_df.to_csv('../sub/test_lgbm_5fold_seed42_v2.csv', index = False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9934301d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458913, 2358)\n"
     ]
    }
   ],
   "source": [
    "seed_everything(CFG.seed)\n",
    "train, test = read_data()\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f33801c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 2356 features...\n",
      "0:\tlearn: 0.6563804\ttest: 0.6562318\tbest: 0.6562318 (0)\ttotal: 63.3ms\tremaining: 10m 32s\n",
      "100:\tlearn: 0.2402303\ttest: 0.2393476\tbest: 0.2393476 (100)\ttotal: 5.72s\tremaining: 9m 21s\n",
      "200:\tlearn: 0.2288250\ttest: 0.2285330\tbest: 0.2285330 (200)\ttotal: 11.3s\tremaining: 9m 8s\n",
      "300:\tlearn: 0.2238839\ttest: 0.2243531\tbest: 0.2243531 (300)\ttotal: 16.8s\tremaining: 9m\n",
      "400:\tlearn: 0.2207308\ttest: 0.2220360\tbest: 0.2220360 (400)\ttotal: 22.3s\tremaining: 8m 53s\n",
      "500:\tlearn: 0.2182962\ttest: 0.2204984\tbest: 0.2204984 (500)\ttotal: 27.7s\tremaining: 8m 46s\n",
      "600:\tlearn: 0.2163246\ttest: 0.2194388\tbest: 0.2194388 (599)\ttotal: 33.1s\tremaining: 8m 38s\n",
      "700:\tlearn: 0.2145994\ttest: 0.2187049\tbest: 0.2187049 (700)\ttotal: 38.5s\tremaining: 8m 31s\n",
      "800:\tlearn: 0.2130946\ttest: 0.2181350\tbest: 0.2181350 (800)\ttotal: 43.9s\tremaining: 8m 23s\n",
      "900:\tlearn: 0.2116648\ttest: 0.2177056\tbest: 0.2177056 (900)\ttotal: 49.3s\tremaining: 8m 17s\n",
      "1000:\tlearn: 0.2103636\ttest: 0.2173181\tbest: 0.2173181 (1000)\ttotal: 54.7s\tremaining: 8m 11s\n",
      "1100:\tlearn: 0.2091395\ttest: 0.2170207\tbest: 0.2170207 (1100)\ttotal: 1m\tremaining: 8m 5s\n",
      "1200:\tlearn: 0.2079349\ttest: 0.2167694\tbest: 0.2167694 (1200)\ttotal: 1m 5s\tremaining: 7m 59s\n",
      "1300:\tlearn: 0.2067782\ttest: 0.2165669\tbest: 0.2165669 (1300)\ttotal: 1m 10s\tremaining: 7m 53s\n",
      "1400:\tlearn: 0.2056607\ttest: 0.2163572\tbest: 0.2163559 (1399)\ttotal: 1m 16s\tremaining: 7m 47s\n",
      "1500:\tlearn: 0.2046651\ttest: 0.2161853\tbest: 0.2161853 (1500)\ttotal: 1m 21s\tremaining: 7m 41s\n",
      "1600:\tlearn: 0.2036093\ttest: 0.2160439\tbest: 0.2160439 (1600)\ttotal: 1m 26s\tremaining: 7m 36s\n",
      "1700:\tlearn: 0.2026243\ttest: 0.2159157\tbest: 0.2159157 (1700)\ttotal: 1m 32s\tremaining: 7m 30s\n",
      "1800:\tlearn: 0.2016612\ttest: 0.2157777\tbest: 0.2157754 (1798)\ttotal: 1m 37s\tremaining: 7m 24s\n",
      "1900:\tlearn: 0.2007452\ttest: 0.2156539\tbest: 0.2156539 (1900)\ttotal: 1m 42s\tremaining: 7m 18s\n",
      "2000:\tlearn: 0.1998149\ttest: 0.2155168\tbest: 0.2155168 (2000)\ttotal: 1m 48s\tremaining: 7m 12s\n",
      "2100:\tlearn: 0.1988765\ttest: 0.2154220\tbest: 0.2154220 (2100)\ttotal: 1m 53s\tremaining: 7m 7s\n",
      "2200:\tlearn: 0.1980058\ttest: 0.2153468\tbest: 0.2153468 (2200)\ttotal: 1m 58s\tremaining: 7m 1s\n",
      "2300:\tlearn: 0.1971169\ttest: 0.2152351\tbest: 0.2152351 (2300)\ttotal: 2m 4s\tremaining: 6m 55s\n",
      "2400:\tlearn: 0.1962298\ttest: 0.2151627\tbest: 0.2151586 (2397)\ttotal: 2m 9s\tremaining: 6m 49s\n",
      "2500:\tlearn: 0.1953263\ttest: 0.2150641\tbest: 0.2150641 (2500)\ttotal: 2m 14s\tremaining: 6m 44s\n",
      "2600:\tlearn: 0.1944558\ttest: 0.2149966\tbest: 0.2149966 (2600)\ttotal: 2m 20s\tremaining: 6m 38s\n",
      "2700:\tlearn: 0.1935931\ttest: 0.2149381\tbest: 0.2149381 (2700)\ttotal: 2m 25s\tremaining: 6m 33s\n",
      "2800:\tlearn: 0.1927360\ttest: 0.2148215\tbest: 0.2148201 (2793)\ttotal: 2m 30s\tremaining: 6m 27s\n",
      "2900:\tlearn: 0.1919122\ttest: 0.2147448\tbest: 0.2147443 (2899)\ttotal: 2m 36s\tremaining: 6m 21s\n",
      "3000:\tlearn: 0.1911000\ttest: 0.2146890\tbest: 0.2146885 (2998)\ttotal: 2m 41s\tremaining: 6m 16s\n",
      "3100:\tlearn: 0.1902954\ttest: 0.2146443\tbest: 0.2146401 (3064)\ttotal: 2m 46s\tremaining: 6m 10s\n",
      "3200:\tlearn: 0.1894980\ttest: 0.2145969\tbest: 0.2145924 (3194)\ttotal: 2m 51s\tremaining: 6m 5s\n",
      "3300:\tlearn: 0.1886904\ttest: 0.2145587\tbest: 0.2145587 (3300)\ttotal: 2m 57s\tremaining: 5m 59s\n",
      "3400:\tlearn: 0.1879088\ttest: 0.2145251\tbest: 0.2145224 (3390)\ttotal: 3m 2s\tremaining: 5m 54s\n",
      "3500:\tlearn: 0.1871209\ttest: 0.2144716\tbest: 0.2144682 (3496)\ttotal: 3m 7s\tremaining: 5m 48s\n",
      "3600:\tlearn: 0.1863551\ttest: 0.2144303\tbest: 0.2144303 (3599)\ttotal: 3m 13s\tremaining: 5m 43s\n",
      "3700:\tlearn: 0.1855656\ttest: 0.2143905\tbest: 0.2143784 (3675)\ttotal: 3m 18s\tremaining: 5m 37s\n",
      "3800:\tlearn: 0.1847879\ttest: 0.2143611\tbest: 0.2143611 (3798)\ttotal: 3m 23s\tremaining: 5m 32s\n",
      "3900:\tlearn: 0.1840056\ttest: 0.2143269\tbest: 0.2143174 (3892)\ttotal: 3m 29s\tremaining: 5m 27s\n",
      "4000:\tlearn: 0.1832361\ttest: 0.2143071\tbest: 0.2143058 (3999)\ttotal: 3m 34s\tremaining: 5m 21s\n",
      "4100:\tlearn: 0.1824404\ttest: 0.2142532\tbest: 0.2142457 (4095)\ttotal: 3m 40s\tremaining: 5m 16s\n",
      "4200:\tlearn: 0.1816825\ttest: 0.2141997\tbest: 0.2141997 (4200)\ttotal: 3m 45s\tremaining: 5m 11s\n",
      "4300:\tlearn: 0.1809384\ttest: 0.2141829\tbest: 0.2141699 (4268)\ttotal: 3m 50s\tremaining: 5m 5s\n",
      "4400:\tlearn: 0.1801854\ttest: 0.2141093\tbest: 0.2141090 (4399)\ttotal: 3m 56s\tremaining: 5m\n",
      "4500:\tlearn: 0.1794307\ttest: 0.2140842\tbest: 0.2140827 (4469)\ttotal: 4m 1s\tremaining: 4m 55s\n",
      "4600:\tlearn: 0.1786971\ttest: 0.2140477\tbest: 0.2140477 (4600)\ttotal: 4m 7s\tremaining: 4m 50s\n",
      "4700:\tlearn: 0.1779660\ttest: 0.2140445\tbest: 0.2140441 (4645)\ttotal: 4m 12s\tremaining: 4m 44s\n",
      "4800:\tlearn: 0.1772601\ttest: 0.2140234\tbest: 0.2140199 (4794)\ttotal: 4m 18s\tremaining: 4m 39s\n",
      "4900:\tlearn: 0.1765423\ttest: 0.2140212\tbest: 0.2140199 (4794)\ttotal: 4m 23s\tremaining: 4m 33s\n",
      "5000:\tlearn: 0.1758413\ttest: 0.2139940\tbest: 0.2139940 (5000)\ttotal: 4m 28s\tremaining: 4m 28s\n",
      "5100:\tlearn: 0.1751278\ttest: 0.2139837\tbest: 0.2139785 (5036)\ttotal: 4m 34s\tremaining: 4m 23s\n",
      "5200:\tlearn: 0.1744231\ttest: 0.2139721\tbest: 0.2139691 (5173)\ttotal: 4m 39s\tremaining: 4m 17s\n",
      "5300:\tlearn: 0.1737360\ttest: 0.2139432\tbest: 0.2139432 (5300)\ttotal: 4m 44s\tremaining: 4m 12s\n",
      "5400:\tlearn: 0.1730038\ttest: 0.2139367\tbest: 0.2139207 (5374)\ttotal: 4m 50s\tremaining: 4m 7s\n",
      "5500:\tlearn: 0.1723004\ttest: 0.2139258\tbest: 0.2139185 (5413)\ttotal: 4m 55s\tremaining: 4m 1s\n",
      "5600:\tlearn: 0.1716405\ttest: 0.2139254\tbest: 0.2139177 (5555)\ttotal: 5m 1s\tremaining: 3m 56s\n",
      "5700:\tlearn: 0.1709784\ttest: 0.2139142\tbest: 0.2139115 (5687)\ttotal: 5m 6s\tremaining: 3m 51s\n",
      "5800:\tlearn: 0.1702665\ttest: 0.2139167\tbest: 0.2138990 (5721)\ttotal: 5m 12s\tremaining: 3m 45s\n",
      "5900:\tlearn: 0.1695969\ttest: 0.2138988\tbest: 0.2138929 (5868)\ttotal: 5m 17s\tremaining: 3m 40s\n",
      "6000:\tlearn: 0.1688816\ttest: 0.2138689\tbest: 0.2138679 (5990)\ttotal: 5m 23s\tremaining: 3m 35s\n",
      "6100:\tlearn: 0.1682018\ttest: 0.2138523\tbest: 0.2138487 (6098)\ttotal: 5m 28s\tremaining: 3m 29s\n",
      "6200:\tlearn: 0.1675397\ttest: 0.2138402\tbest: 0.2138318 (6167)\ttotal: 5m 34s\tremaining: 3m 24s\n",
      "6300:\tlearn: 0.1668695\ttest: 0.2138260\tbest: 0.2138118 (6285)\ttotal: 5m 39s\tremaining: 3m 19s\n",
      "6400:\tlearn: 0.1662259\ttest: 0.2137903\tbest: 0.2137903 (6400)\ttotal: 5m 44s\tremaining: 3m 13s\n",
      "6500:\tlearn: 0.1655773\ttest: 0.2138024\tbest: 0.2137867 (6406)\ttotal: 5m 50s\tremaining: 3m 8s\n",
      "6600:\tlearn: 0.1649131\ttest: 0.2138001\tbest: 0.2137867 (6406)\ttotal: 5m 55s\tremaining: 3m 3s\n",
      "6700:\tlearn: 0.1642527\ttest: 0.2138031\tbest: 0.2137862 (6648)\ttotal: 6m\tremaining: 2m 57s\n",
      "6800:\tlearn: 0.1636391\ttest: 0.2138059\tbest: 0.2137835 (6736)\ttotal: 6m 6s\tremaining: 2m 52s\n",
      "6900:\tlearn: 0.1629754\ttest: 0.2137799\tbest: 0.2137781 (6892)\ttotal: 6m 11s\tremaining: 2m 46s\n",
      "7000:\tlearn: 0.1623229\ttest: 0.2137988\tbest: 0.2137765 (6915)\ttotal: 6m 17s\tremaining: 2m 41s\n",
      "7100:\tlearn: 0.1616747\ttest: 0.2137965\tbest: 0.2137765 (6915)\ttotal: 6m 22s\tremaining: 2m 36s\n",
      "7200:\tlearn: 0.1610460\ttest: 0.2137695\tbest: 0.2137679 (7195)\ttotal: 6m 27s\tremaining: 2m 30s\n",
      "7300:\tlearn: 0.1603885\ttest: 0.2137567\tbest: 0.2137535 (7296)\ttotal: 6m 33s\tremaining: 2m 25s\n",
      "7400:\tlearn: 0.1597500\ttest: 0.2137662\tbest: 0.2137535 (7296)\ttotal: 6m 38s\tremaining: 2m 19s\n",
      "7500:\tlearn: 0.1591387\ttest: 0.2137696\tbest: 0.2137535 (7296)\ttotal: 6m 43s\tremaining: 2m 14s\n",
      "7600:\tlearn: 0.1585232\ttest: 0.2137369\tbest: 0.2137348 (7595)\ttotal: 6m 49s\tremaining: 2m 9s\n",
      "7700:\tlearn: 0.1579147\ttest: 0.2137387\tbest: 0.2137301 (7645)\ttotal: 6m 54s\tremaining: 2m 3s\n",
      "7800:\tlearn: 0.1573452\ttest: 0.2137433\tbest: 0.2137257 (7782)\ttotal: 6m 59s\tremaining: 1m 58s\n",
      "7900:\tlearn: 0.1567573\ttest: 0.2137595\tbest: 0.2137257 (7782)\ttotal: 7m 5s\tremaining: 1m 52s\n",
      "8000:\tlearn: 0.1561611\ttest: 0.2137488\tbest: 0.2137257 (7782)\ttotal: 7m 10s\tremaining: 1m 47s\n",
      "8100:\tlearn: 0.1555431\ttest: 0.2137534\tbest: 0.2137257 (7782)\ttotal: 7m 15s\tremaining: 1m 42s\n",
      "8200:\tlearn: 0.1549707\ttest: 0.2137827\tbest: 0.2137257 (7782)\ttotal: 7m 21s\tremaining: 1m 36s\n",
      "8300:\tlearn: 0.1543708\ttest: 0.2137972\tbest: 0.2137257 (7782)\ttotal: 7m 26s\tremaining: 1m 31s\n",
      "8400:\tlearn: 0.1538194\ttest: 0.2137863\tbest: 0.2137257 (7782)\ttotal: 7m 32s\tremaining: 1m 26s\n",
      "8500:\tlearn: 0.1532356\ttest: 0.2137838\tbest: 0.2137257 (7782)\ttotal: 7m 37s\tremaining: 1m 20s\n",
      "8600:\tlearn: 0.1526713\ttest: 0.2137925\tbest: 0.2137257 (7782)\ttotal: 7m 42s\tremaining: 1m 15s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8700:\tlearn: 0.1520688\ttest: 0.2138012\tbest: 0.2137257 (7782)\ttotal: 7m 48s\tremaining: 1m 9s\n",
      "8800:\tlearn: 0.1514877\ttest: 0.2138200\tbest: 0.2137257 (7782)\ttotal: 7m 53s\tremaining: 1m 4s\n",
      "8900:\tlearn: 0.1509393\ttest: 0.2138227\tbest: 0.2137257 (7782)\ttotal: 7m 58s\tremaining: 59.1s\n",
      "9000:\tlearn: 0.1503637\ttest: 0.2138345\tbest: 0.2137257 (7782)\ttotal: 8m 4s\tremaining: 53.8s\n",
      "9100:\tlearn: 0.1497938\ttest: 0.2138349\tbest: 0.2137257 (7782)\ttotal: 8m 9s\tremaining: 48.4s\n",
      "9200:\tlearn: 0.1492514\ttest: 0.2138466\tbest: 0.2137257 (7782)\ttotal: 8m 15s\tremaining: 43s\n",
      "9300:\tlearn: 0.1486969\ttest: 0.2138436\tbest: 0.2137257 (7782)\ttotal: 8m 20s\tremaining: 37.6s\n",
      "9400:\tlearn: 0.1481560\ttest: 0.2138434\tbest: 0.2137257 (7782)\ttotal: 8m 26s\tremaining: 32.2s\n",
      "9500:\tlearn: 0.1476203\ttest: 0.2138775\tbest: 0.2137257 (7782)\ttotal: 8m 31s\tremaining: 26.9s\n",
      "9600:\tlearn: 0.1470711\ttest: 0.2138733\tbest: 0.2137257 (7782)\ttotal: 8m 36s\tremaining: 21.5s\n",
      "9700:\tlearn: 0.1464986\ttest: 0.2138585\tbest: 0.2137257 (7782)\ttotal: 8m 42s\tremaining: 16.1s\n",
      "9800:\tlearn: 0.1459446\ttest: 0.2138406\tbest: 0.2137257 (7782)\ttotal: 8m 47s\tremaining: 10.7s\n",
      "9900:\tlearn: 0.1453820\ttest: 0.2138563\tbest: 0.2137257 (7782)\ttotal: 8m 53s\tremaining: 5.33s\n",
      "9999:\tlearn: 0.1448422\ttest: 0.2138618\tbest: 0.2137257 (7782)\ttotal: 8m 58s\tremaining: 0us\n",
      "bestTest = 0.2137257299\n",
      "bestIteration = 7782\n",
      "Shrink model to first 7783 iterations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae57bef33b547a4b8dd857e3311ad64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our fold 0 CV score is 0.8012420303906174\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 2356 features...\n",
      "0:\tlearn: 0.6561923\ttest: 0.6561567\tbest: 0.6561567 (0)\ttotal: 250ms\tremaining: 41m 44s\n",
      "100:\tlearn: 0.2396201\ttest: 0.2410770\tbest: 0.2410770 (100)\ttotal: 6.23s\tremaining: 10m 10s\n",
      "200:\tlearn: 0.2280419\ttest: 0.2308644\tbest: 0.2308644 (200)\ttotal: 12.1s\tremaining: 9m 48s\n",
      "300:\tlearn: 0.2230345\ttest: 0.2269370\tbest: 0.2269370 (300)\ttotal: 18s\tremaining: 9m 39s\n",
      "400:\tlearn: 0.2197767\ttest: 0.2246839\tbest: 0.2246839 (400)\ttotal: 23.7s\tremaining: 9m 28s\n",
      "500:\tlearn: 0.2173276\ttest: 0.2232986\tbest: 0.2232986 (500)\ttotal: 29.6s\tremaining: 9m 21s\n",
      "600:\tlearn: 0.2152865\ttest: 0.2223534\tbest: 0.2223534 (600)\ttotal: 35.4s\tremaining: 9m 14s\n",
      "700:\tlearn: 0.2135718\ttest: 0.2217101\tbest: 0.2217101 (700)\ttotal: 41.2s\tremaining: 9m 7s\n",
      "800:\tlearn: 0.2120168\ttest: 0.2212069\tbest: 0.2212069 (800)\ttotal: 46.9s\tremaining: 8m 58s\n",
      "900:\tlearn: 0.2106323\ttest: 0.2208514\tbest: 0.2208514 (900)\ttotal: 52.4s\tremaining: 8m 49s\n",
      "1000:\tlearn: 0.2093628\ttest: 0.2205118\tbest: 0.2205109 (999)\ttotal: 58s\tremaining: 8m 41s\n",
      "1100:\tlearn: 0.2081816\ttest: 0.2202465\tbest: 0.2202465 (1099)\ttotal: 1m 3s\tremaining: 8m 34s\n",
      "1200:\tlearn: 0.2070180\ttest: 0.2199980\tbest: 0.2199979 (1198)\ttotal: 1m 9s\tremaining: 8m 27s\n",
      "1300:\tlearn: 0.2059166\ttest: 0.2197931\tbest: 0.2197931 (1300)\ttotal: 1m 14s\tremaining: 8m 20s\n",
      "1400:\tlearn: 0.2047911\ttest: 0.2196011\tbest: 0.2196003 (1399)\ttotal: 1m 20s\tremaining: 8m 14s\n",
      "1500:\tlearn: 0.2037628\ttest: 0.2194515\tbest: 0.2194515 (1500)\ttotal: 1m 26s\tremaining: 8m 7s\n",
      "1600:\tlearn: 0.2027664\ttest: 0.2193194\tbest: 0.2193179 (1595)\ttotal: 1m 31s\tremaining: 8m\n",
      "1700:\tlearn: 0.2017534\ttest: 0.2191733\tbest: 0.2191719 (1694)\ttotal: 1m 37s\tremaining: 7m 54s\n",
      "1800:\tlearn: 0.2007595\ttest: 0.2190678\tbest: 0.2190678 (1800)\ttotal: 1m 43s\tremaining: 7m 49s\n",
      "1900:\tlearn: 0.1997846\ttest: 0.2189858\tbest: 0.2189858 (1900)\ttotal: 1m 48s\tremaining: 7m 43s\n",
      "2000:\tlearn: 0.1988668\ttest: 0.2188923\tbest: 0.2188874 (1982)\ttotal: 1m 54s\tremaining: 7m 36s\n",
      "2100:\tlearn: 0.1979468\ttest: 0.2188526\tbest: 0.2188515 (2077)\ttotal: 1m 59s\tremaining: 7m 30s\n",
      "2200:\tlearn: 0.1970519\ttest: 0.2187884\tbest: 0.2187880 (2194)\ttotal: 2m 5s\tremaining: 7m 23s\n",
      "2300:\tlearn: 0.1961547\ttest: 0.2186968\tbest: 0.2186968 (2300)\ttotal: 2m 10s\tremaining: 7m 17s\n",
      "2400:\tlearn: 0.1952684\ttest: 0.2186085\tbest: 0.2186085 (2400)\ttotal: 2m 16s\tremaining: 7m 11s\n",
      "2500:\tlearn: 0.1944075\ttest: 0.2185567\tbest: 0.2185514 (2476)\ttotal: 2m 21s\tremaining: 7m 5s\n",
      "2600:\tlearn: 0.1935275\ttest: 0.2184814\tbest: 0.2184814 (2600)\ttotal: 2m 27s\tremaining: 6m 59s\n",
      "2700:\tlearn: 0.1926530\ttest: 0.2184096\tbest: 0.2184096 (2700)\ttotal: 2m 33s\tremaining: 6m 53s\n",
      "2800:\tlearn: 0.1918349\ttest: 0.2183804\tbest: 0.2183678 (2782)\ttotal: 2m 38s\tremaining: 6m 47s\n",
      "2900:\tlearn: 0.1909986\ttest: 0.2183466\tbest: 0.2183466 (2900)\ttotal: 2m 44s\tremaining: 6m 41s\n",
      "3000:\tlearn: 0.1901841\ttest: 0.2183003\tbest: 0.2183003 (3000)\ttotal: 2m 49s\tremaining: 6m 35s\n",
      "3100:\tlearn: 0.1893500\ttest: 0.2182609\tbest: 0.2182593 (3099)\ttotal: 2m 55s\tremaining: 6m 29s\n",
      "3200:\tlearn: 0.1885330\ttest: 0.2182363\tbest: 0.2182359 (3199)\ttotal: 3m\tremaining: 6m 23s\n",
      "3300:\tlearn: 0.1877470\ttest: 0.2181966\tbest: 0.2181937 (3296)\ttotal: 3m 6s\tremaining: 6m 17s\n",
      "3400:\tlearn: 0.1869235\ttest: 0.2181457\tbest: 0.2181457 (3400)\ttotal: 3m 11s\tremaining: 6m 11s\n",
      "3500:\tlearn: 0.1861326\ttest: 0.2181208\tbest: 0.2181181 (3497)\ttotal: 3m 17s\tremaining: 6m 6s\n",
      "3600:\tlearn: 0.1853382\ttest: 0.2180713\tbest: 0.2180675 (3585)\ttotal: 3m 22s\tremaining: 6m\n",
      "3700:\tlearn: 0.1845351\ttest: 0.2180504\tbest: 0.2180503 (3698)\ttotal: 3m 28s\tremaining: 5m 54s\n",
      "3800:\tlearn: 0.1837422\ttest: 0.2180000\tbest: 0.2179960 (3798)\ttotal: 3m 33s\tremaining: 5m 48s\n",
      "3900:\tlearn: 0.1829649\ttest: 0.2179587\tbest: 0.2179587 (3900)\ttotal: 3m 39s\tremaining: 5m 43s\n",
      "4000:\tlearn: 0.1822257\ttest: 0.2179408\tbest: 0.2179399 (3992)\ttotal: 3m 45s\tremaining: 5m 37s\n",
      "4100:\tlearn: 0.1815001\ttest: 0.2179102\tbest: 0.2179102 (4100)\ttotal: 3m 50s\tremaining: 5m 31s\n",
      "4200:\tlearn: 0.1807782\ttest: 0.2178957\tbest: 0.2178940 (4192)\ttotal: 3m 55s\tremaining: 5m 25s\n",
      "4300:\tlearn: 0.1800266\ttest: 0.2178644\tbest: 0.2178612 (4294)\ttotal: 4m 1s\tremaining: 5m 19s\n",
      "4400:\tlearn: 0.1792982\ttest: 0.2178359\tbest: 0.2178219 (4367)\ttotal: 4m 6s\tremaining: 5m 14s\n",
      "4500:\tlearn: 0.1785728\ttest: 0.2178382\tbest: 0.2178219 (4367)\ttotal: 4m 12s\tremaining: 5m 8s\n",
      "4600:\tlearn: 0.1778068\ttest: 0.2178042\tbest: 0.2177932 (4590)\ttotal: 4m 17s\tremaining: 5m 2s\n",
      "4700:\tlearn: 0.1771017\ttest: 0.2178070\tbest: 0.2177859 (4629)\ttotal: 4m 23s\tremaining: 4m 56s\n",
      "4800:\tlearn: 0.1763735\ttest: 0.2177972\tbest: 0.2177859 (4629)\ttotal: 4m 28s\tremaining: 4m 50s\n",
      "4900:\tlearn: 0.1756690\ttest: 0.2177852\tbest: 0.2177842 (4853)\ttotal: 4m 34s\tremaining: 4m 45s\n",
      "5000:\tlearn: 0.1749833\ttest: 0.2177580\tbest: 0.2177554 (4995)\ttotal: 4m 39s\tremaining: 4m 39s\n",
      "5100:\tlearn: 0.1742644\ttest: 0.2177523\tbest: 0.2177371 (5042)\ttotal: 4m 45s\tremaining: 4m 33s\n",
      "5200:\tlearn: 0.1735686\ttest: 0.2177457\tbest: 0.2177330 (5158)\ttotal: 4m 50s\tremaining: 4m 28s\n",
      "5300:\tlearn: 0.1728880\ttest: 0.2177338\tbest: 0.2177288 (5296)\ttotal: 4m 56s\tremaining: 4m 22s\n",
      "5400:\tlearn: 0.1721911\ttest: 0.2177103\tbest: 0.2177078 (5379)\ttotal: 5m 1s\tremaining: 4m 16s\n",
      "5500:\tlearn: 0.1715273\ttest: 0.2176935\tbest: 0.2176884 (5468)\ttotal: 5m 7s\tremaining: 4m 11s\n",
      "5600:\tlearn: 0.1708395\ttest: 0.2176901\tbest: 0.2176675 (5558)\ttotal: 5m 12s\tremaining: 4m 5s\n",
      "5700:\tlearn: 0.1701569\ttest: 0.2176907\tbest: 0.2176675 (5558)\ttotal: 5m 18s\tremaining: 4m\n",
      "5800:\tlearn: 0.1695121\ttest: 0.2176830\tbest: 0.2176675 (5558)\ttotal: 5m 23s\tremaining: 3m 54s\n",
      "5900:\tlearn: 0.1688407\ttest: 0.2176643\tbest: 0.2176628 (5896)\ttotal: 5m 29s\tremaining: 3m 48s\n",
      "6000:\tlearn: 0.1681710\ttest: 0.2176531\tbest: 0.2176463 (5968)\ttotal: 5m 34s\tremaining: 3m 43s\n",
      "6100:\tlearn: 0.1675002\ttest: 0.2176473\tbest: 0.2176367 (6023)\ttotal: 5m 40s\tremaining: 3m 37s\n",
      "6200:\tlearn: 0.1668575\ttest: 0.2176461\tbest: 0.2176349 (6170)\ttotal: 5m 45s\tremaining: 3m 31s\n",
      "6300:\tlearn: 0.1661809\ttest: 0.2176337\tbest: 0.2176257 (6277)\ttotal: 5m 51s\tremaining: 3m 26s\n",
      "6400:\tlearn: 0.1655240\ttest: 0.2176408\tbest: 0.2176242 (6358)\ttotal: 5m 56s\tremaining: 3m 20s\n",
      "6500:\tlearn: 0.1648647\ttest: 0.2176716\tbest: 0.2176242 (6358)\ttotal: 6m 2s\tremaining: 3m 15s\n",
      "6600:\tlearn: 0.1642325\ttest: 0.2176996\tbest: 0.2176242 (6358)\ttotal: 6m 7s\tremaining: 3m 9s\n",
      "6700:\tlearn: 0.1636131\ttest: 0.2177175\tbest: 0.2176242 (6358)\ttotal: 6m 13s\tremaining: 3m 3s\n",
      "6800:\tlearn: 0.1629864\ttest: 0.2177197\tbest: 0.2176242 (6358)\ttotal: 6m 18s\tremaining: 2m 58s\n",
      "6900:\tlearn: 0.1623716\ttest: 0.2177088\tbest: 0.2176242 (6358)\ttotal: 6m 24s\tremaining: 2m 52s\n",
      "7000:\tlearn: 0.1617438\ttest: 0.2177196\tbest: 0.2176242 (6358)\ttotal: 6m 29s\tremaining: 2m 47s\n",
      "7100:\tlearn: 0.1611177\ttest: 0.2177162\tbest: 0.2176242 (6358)\ttotal: 6m 35s\tremaining: 2m 41s\n",
      "7200:\tlearn: 0.1605052\ttest: 0.2177268\tbest: 0.2176242 (6358)\ttotal: 6m 40s\tremaining: 2m 35s\n",
      "7300:\tlearn: 0.1598774\ttest: 0.2177352\tbest: 0.2176242 (6358)\ttotal: 6m 46s\tremaining: 2m 30s\n",
      "7400:\tlearn: 0.1592533\ttest: 0.2177377\tbest: 0.2176242 (6358)\ttotal: 6m 51s\tremaining: 2m 24s\n",
      "7500:\tlearn: 0.1586459\ttest: 0.2177353\tbest: 0.2176242 (6358)\ttotal: 6m 57s\tremaining: 2m 19s\n",
      "7600:\tlearn: 0.1580763\ttest: 0.2177465\tbest: 0.2176242 (6358)\ttotal: 7m 2s\tremaining: 2m 13s\n",
      "7700:\tlearn: 0.1574698\ttest: 0.2177287\tbest: 0.2176242 (6358)\ttotal: 7m 8s\tremaining: 2m 7s\n",
      "7800:\tlearn: 0.1568540\ttest: 0.2177247\tbest: 0.2176242 (6358)\ttotal: 7m 14s\tremaining: 2m 2s\n",
      "7900:\tlearn: 0.1562700\ttest: 0.2177050\tbest: 0.2176242 (6358)\ttotal: 7m 19s\tremaining: 1m 56s\n",
      "8000:\tlearn: 0.1556419\ttest: 0.2177001\tbest: 0.2176242 (6358)\ttotal: 7m 25s\tremaining: 1m 51s\n",
      "8100:\tlearn: 0.1550735\ttest: 0.2177095\tbest: 0.2176242 (6358)\ttotal: 7m 30s\tremaining: 1m 45s\n",
      "8200:\tlearn: 0.1544694\ttest: 0.2177350\tbest: 0.2176242 (6358)\ttotal: 7m 36s\tremaining: 1m 40s\n",
      "8300:\tlearn: 0.1538950\ttest: 0.2177714\tbest: 0.2176242 (6358)\ttotal: 7m 41s\tremaining: 1m 34s\n",
      "8400:\tlearn: 0.1533223\ttest: 0.2177786\tbest: 0.2176242 (6358)\ttotal: 7m 47s\tremaining: 1m 28s\n",
      "8500:\tlearn: 0.1527204\ttest: 0.2177925\tbest: 0.2176242 (6358)\ttotal: 7m 52s\tremaining: 1m 23s\n",
      "8600:\tlearn: 0.1521469\ttest: 0.2178005\tbest: 0.2176242 (6358)\ttotal: 7m 58s\tremaining: 1m 17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8700:\tlearn: 0.1515696\ttest: 0.2177902\tbest: 0.2176242 (6358)\ttotal: 8m 3s\tremaining: 1m 12s\n",
      "8800:\tlearn: 0.1510364\ttest: 0.2177942\tbest: 0.2176242 (6358)\ttotal: 8m 9s\tremaining: 1m 6s\n",
      "8900:\tlearn: 0.1504559\ttest: 0.2177900\tbest: 0.2176242 (6358)\ttotal: 8m 14s\tremaining: 1m 1s\n",
      "9000:\tlearn: 0.1499073\ttest: 0.2177859\tbest: 0.2176242 (6358)\ttotal: 8m 20s\tremaining: 55.5s\n",
      "9100:\tlearn: 0.1493553\ttest: 0.2177829\tbest: 0.2176242 (6358)\ttotal: 8m 25s\tremaining: 49.9s\n",
      "9200:\tlearn: 0.1487901\ttest: 0.2177772\tbest: 0.2176242 (6358)\ttotal: 8m 31s\tremaining: 44.4s\n",
      "9300:\tlearn: 0.1482045\ttest: 0.2177895\tbest: 0.2176242 (6358)\ttotal: 8m 36s\tremaining: 38.8s\n",
      "9400:\tlearn: 0.1476455\ttest: 0.2178073\tbest: 0.2176242 (6358)\ttotal: 8m 42s\tremaining: 33.3s\n",
      "9500:\tlearn: 0.1471038\ttest: 0.2178108\tbest: 0.2176242 (6358)\ttotal: 8m 47s\tremaining: 27.7s\n",
      "9600:\tlearn: 0.1465508\ttest: 0.2178437\tbest: 0.2176242 (6358)\ttotal: 8m 53s\tremaining: 22.2s\n",
      "9700:\tlearn: 0.1459970\ttest: 0.2178598\tbest: 0.2176242 (6358)\ttotal: 8m 58s\tremaining: 16.6s\n",
      "9800:\tlearn: 0.1454750\ttest: 0.2178695\tbest: 0.2176242 (6358)\ttotal: 9m 3s\tremaining: 11s\n",
      "9900:\tlearn: 0.1449428\ttest: 0.2179016\tbest: 0.2176242 (6358)\ttotal: 9m 9s\tremaining: 5.49s\n",
      "9999:\tlearn: 0.1444185\ttest: 0.2178991\tbest: 0.2176242 (6358)\ttotal: 9m 14s\tremaining: 0us\n",
      "bestTest = 0.2176241915\n",
      "bestIteration = 6358\n",
      "Shrink model to first 6359 iterations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25fd3bd69d0e4ee6874d7873178598e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our fold 1 CV score is 0.7920508854200967\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 2356 features...\n",
      "0:\tlearn: 0.6558370\ttest: 0.6559445\tbest: 0.6559445 (0)\ttotal: 339ms\tremaining: 56m 25s\n",
      "100:\tlearn: 0.2398455\ttest: 0.2416623\tbest: 0.2416623 (100)\ttotal: 6.17s\tremaining: 10m 5s\n",
      "200:\tlearn: 0.2282743\ttest: 0.2311625\tbest: 0.2311625 (200)\ttotal: 11.9s\tremaining: 9m 41s\n",
      "300:\tlearn: 0.2232106\ttest: 0.2271367\tbest: 0.2271367 (300)\ttotal: 17.6s\tremaining: 9m 26s\n",
      "400:\tlearn: 0.2200058\ttest: 0.2248935\tbest: 0.2248935 (400)\ttotal: 23.3s\tremaining: 9m 17s\n",
      "500:\tlearn: 0.2176111\ttest: 0.2234475\tbest: 0.2234475 (500)\ttotal: 28.9s\tremaining: 9m 7s\n",
      "600:\tlearn: 0.2156354\ttest: 0.2224493\tbest: 0.2224493 (600)\ttotal: 34.4s\tremaining: 8m 58s\n",
      "700:\tlearn: 0.2139303\ttest: 0.2217245\tbest: 0.2217245 (700)\ttotal: 40s\tremaining: 8m 50s\n",
      "800:\tlearn: 0.2123990\ttest: 0.2211750\tbest: 0.2211750 (800)\ttotal: 45.5s\tremaining: 8m 42s\n",
      "900:\tlearn: 0.2110026\ttest: 0.2207154\tbest: 0.2207154 (900)\ttotal: 51s\tremaining: 8m 34s\n",
      "1000:\tlearn: 0.2096692\ttest: 0.2203570\tbest: 0.2203570 (1000)\ttotal: 56.5s\tremaining: 8m 27s\n",
      "1100:\tlearn: 0.2084885\ttest: 0.2200373\tbest: 0.2200373 (1100)\ttotal: 1m 1s\tremaining: 8m 20s\n",
      "1200:\tlearn: 0.2073401\ttest: 0.2197627\tbest: 0.2197627 (1200)\ttotal: 1m 7s\tremaining: 8m 13s\n",
      "1300:\tlearn: 0.2061989\ttest: 0.2195522\tbest: 0.2195522 (1300)\ttotal: 1m 12s\tremaining: 8m 7s\n",
      "1400:\tlearn: 0.2051306\ttest: 0.2193358\tbest: 0.2193358 (1400)\ttotal: 1m 18s\tremaining: 8m\n",
      "1500:\tlearn: 0.2040853\ttest: 0.2192132\tbest: 0.2192113 (1499)\ttotal: 1m 23s\tremaining: 7m 54s\n",
      "1600:\tlearn: 0.2030619\ttest: 0.2190340\tbest: 0.2190340 (1600)\ttotal: 1m 29s\tremaining: 7m 48s\n",
      "1700:\tlearn: 0.2020481\ttest: 0.2189240\tbest: 0.2189216 (1680)\ttotal: 1m 34s\tremaining: 7m 42s\n",
      "1800:\tlearn: 0.2010847\ttest: 0.2187593\tbest: 0.2187593 (1800)\ttotal: 1m 40s\tremaining: 7m 35s\n",
      "1900:\tlearn: 0.2001498\ttest: 0.2186386\tbest: 0.2186386 (1900)\ttotal: 1m 45s\tremaining: 7m 29s\n",
      "2000:\tlearn: 0.1992279\ttest: 0.2185065\tbest: 0.2185065 (2000)\ttotal: 1m 50s\tremaining: 7m 23s\n",
      "2100:\tlearn: 0.1982952\ttest: 0.2184335\tbest: 0.2184331 (2095)\ttotal: 1m 56s\tremaining: 7m 17s\n",
      "2200:\tlearn: 0.1974062\ttest: 0.2183511\tbest: 0.2183486 (2193)\ttotal: 2m 1s\tremaining: 7m 11s\n",
      "2300:\tlearn: 0.1965156\ttest: 0.2182424\tbest: 0.2182424 (2300)\ttotal: 2m 7s\tremaining: 7m 5s\n",
      "2400:\tlearn: 0.1956494\ttest: 0.2181626\tbest: 0.2181620 (2399)\ttotal: 2m 12s\tremaining: 6m 59s\n",
      "2500:\tlearn: 0.1947826\ttest: 0.2180873\tbest: 0.2180862 (2497)\ttotal: 2m 18s\tremaining: 6m 54s\n",
      "2600:\tlearn: 0.1939653\ttest: 0.2180291\tbest: 0.2180289 (2598)\ttotal: 2m 23s\tremaining: 6m 48s\n",
      "2700:\tlearn: 0.1931252\ttest: 0.2179659\tbest: 0.2179640 (2696)\ttotal: 2m 29s\tremaining: 6m 43s\n",
      "2800:\tlearn: 0.1922695\ttest: 0.2178844\tbest: 0.2178841 (2799)\ttotal: 2m 34s\tremaining: 6m 37s\n",
      "2900:\tlearn: 0.1914197\ttest: 0.2177905\tbest: 0.2177885 (2899)\ttotal: 2m 40s\tremaining: 6m 32s\n",
      "3000:\tlearn: 0.1905584\ttest: 0.2177435\tbest: 0.2177435 (3000)\ttotal: 2m 45s\tremaining: 6m 26s\n",
      "3100:\tlearn: 0.1897639\ttest: 0.2176632\tbest: 0.2176616 (3099)\ttotal: 2m 51s\tremaining: 6m 21s\n",
      "3200:\tlearn: 0.1889527\ttest: 0.2175709\tbest: 0.2175685 (3195)\ttotal: 2m 56s\tremaining: 6m 15s\n",
      "3300:\tlearn: 0.1881292\ttest: 0.2175234\tbest: 0.2175229 (3298)\ttotal: 3m 2s\tremaining: 6m 10s\n",
      "3400:\tlearn: 0.1873482\ttest: 0.2174745\tbest: 0.2174712 (3396)\ttotal: 3m 8s\tremaining: 6m 4s\n",
      "3500:\tlearn: 0.1865940\ttest: 0.2174276\tbest: 0.2174269 (3498)\ttotal: 3m 13s\tremaining: 5m 59s\n",
      "3600:\tlearn: 0.1857931\ttest: 0.2174031\tbest: 0.2174031 (3600)\ttotal: 3m 19s\tremaining: 5m 53s\n",
      "3700:\tlearn: 0.1850175\ttest: 0.2173627\tbest: 0.2173618 (3696)\ttotal: 3m 24s\tremaining: 5m 48s\n",
      "3800:\tlearn: 0.1842499\ttest: 0.2173094\tbest: 0.2173083 (3799)\ttotal: 3m 30s\tremaining: 5m 42s\n",
      "3900:\tlearn: 0.1834949\ttest: 0.2172892\tbest: 0.2172873 (3892)\ttotal: 3m 35s\tremaining: 5m 37s\n",
      "4000:\tlearn: 0.1827344\ttest: 0.2172430\tbest: 0.2172422 (3999)\ttotal: 3m 41s\tremaining: 5m 31s\n",
      "4100:\tlearn: 0.1819944\ttest: 0.2171922\tbest: 0.2171890 (4082)\ttotal: 3m 46s\tremaining: 5m 26s\n",
      "4200:\tlearn: 0.1812431\ttest: 0.2171280\tbest: 0.2171280 (4200)\ttotal: 3m 52s\tremaining: 5m 20s\n",
      "4300:\tlearn: 0.1804892\ttest: 0.2170919\tbest: 0.2170919 (4300)\ttotal: 3m 57s\tremaining: 5m 15s\n",
      "4400:\tlearn: 0.1797582\ttest: 0.2170737\tbest: 0.2170656 (4385)\ttotal: 4m 3s\tremaining: 5m 9s\n",
      "4500:\tlearn: 0.1790317\ttest: 0.2170702\tbest: 0.2170612 (4444)\ttotal: 4m 9s\tremaining: 5m 4s\n",
      "4600:\tlearn: 0.1782988\ttest: 0.2170392\tbest: 0.2170392 (4600)\ttotal: 4m 14s\tremaining: 4m 58s\n",
      "4700:\tlearn: 0.1775646\ttest: 0.2170392\tbest: 0.2170346 (4685)\ttotal: 4m 19s\tremaining: 4m 53s\n",
      "4800:\tlearn: 0.1767880\ttest: 0.2170361\tbest: 0.2170311 (4712)\ttotal: 4m 25s\tremaining: 4m 47s\n",
      "4900:\tlearn: 0.1761053\ttest: 0.2170225\tbest: 0.2170225 (4900)\ttotal: 4m 30s\tremaining: 4m 41s\n",
      "5000:\tlearn: 0.1753891\ttest: 0.2169735\tbest: 0.2169735 (5000)\ttotal: 4m 36s\tremaining: 4m 36s\n",
      "5100:\tlearn: 0.1746641\ttest: 0.2169469\tbest: 0.2169450 (5076)\ttotal: 4m 42s\tremaining: 4m 30s\n",
      "5200:\tlearn: 0.1739687\ttest: 0.2169337\tbest: 0.2169283 (5195)\ttotal: 4m 47s\tremaining: 4m 25s\n",
      "5300:\tlearn: 0.1732748\ttest: 0.2169385\tbest: 0.2169283 (5195)\ttotal: 4m 53s\tremaining: 4m 19s\n",
      "5400:\tlearn: 0.1725905\ttest: 0.2169366\tbest: 0.2169283 (5195)\ttotal: 4m 58s\tremaining: 4m 14s\n",
      "5500:\tlearn: 0.1719187\ttest: 0.2169172\tbest: 0.2169111 (5475)\ttotal: 5m 3s\tremaining: 4m 8s\n",
      "5600:\tlearn: 0.1712625\ttest: 0.2169232\tbest: 0.2169074 (5554)\ttotal: 5m 9s\tremaining: 4m 2s\n",
      "5700:\tlearn: 0.1705728\ttest: 0.2169148\tbest: 0.2169018 (5656)\ttotal: 5m 14s\tremaining: 3m 57s\n",
      "5800:\tlearn: 0.1698685\ttest: 0.2169042\tbest: 0.2168921 (5756)\ttotal: 5m 20s\tremaining: 3m 51s\n",
      "5900:\tlearn: 0.1692181\ttest: 0.2169015\tbest: 0.2168921 (5756)\ttotal: 5m 25s\tremaining: 3m 46s\n",
      "6000:\tlearn: 0.1685539\ttest: 0.2169068\tbest: 0.2168921 (5756)\ttotal: 5m 31s\tremaining: 3m 40s\n",
      "6100:\tlearn: 0.1679020\ttest: 0.2168766\tbest: 0.2168688 (6082)\ttotal: 5m 36s\tremaining: 3m 35s\n",
      "6200:\tlearn: 0.1672380\ttest: 0.2168555\tbest: 0.2168555 (6200)\ttotal: 5m 41s\tremaining: 3m 29s\n",
      "6300:\tlearn: 0.1666260\ttest: 0.2168459\tbest: 0.2168457 (6297)\ttotal: 5m 47s\tremaining: 3m 23s\n",
      "6400:\tlearn: 0.1659585\ttest: 0.2168369\tbest: 0.2168367 (6399)\ttotal: 5m 52s\tremaining: 3m 18s\n",
      "6500:\tlearn: 0.1653365\ttest: 0.2168442\tbest: 0.2168257 (6443)\ttotal: 5m 58s\tremaining: 3m 12s\n",
      "6600:\tlearn: 0.1646748\ttest: 0.2168441\tbest: 0.2168257 (6443)\ttotal: 6m 3s\tremaining: 3m 7s\n",
      "6700:\tlearn: 0.1640406\ttest: 0.2168383\tbest: 0.2168257 (6443)\ttotal: 6m 9s\tremaining: 3m 1s\n",
      "6800:\tlearn: 0.1634147\ttest: 0.2168291\tbest: 0.2168250 (6797)\ttotal: 6m 14s\tremaining: 2m 56s\n",
      "6900:\tlearn: 0.1627874\ttest: 0.2168181\tbest: 0.2168130 (6869)\ttotal: 6m 20s\tremaining: 2m 50s\n",
      "7000:\tlearn: 0.1621603\ttest: 0.2168224\tbest: 0.2168130 (6869)\ttotal: 6m 26s\tremaining: 2m 45s\n",
      "7100:\tlearn: 0.1615535\ttest: 0.2168283\tbest: 0.2168127 (7067)\ttotal: 6m 31s\tremaining: 2m 39s\n",
      "7200:\tlearn: 0.1609235\ttest: 0.2168270\tbest: 0.2168084 (7136)\ttotal: 6m 37s\tremaining: 2m 34s\n",
      "7300:\tlearn: 0.1602935\ttest: 0.2168323\tbest: 0.2168084 (7136)\ttotal: 6m 42s\tremaining: 2m 28s\n",
      "7400:\tlearn: 0.1596612\ttest: 0.2168281\tbest: 0.2168065 (7369)\ttotal: 6m 48s\tremaining: 2m 23s\n",
      "7500:\tlearn: 0.1590405\ttest: 0.2168292\tbest: 0.2168065 (7369)\ttotal: 6m 53s\tremaining: 2m 17s\n",
      "7600:\tlearn: 0.1584633\ttest: 0.2168220\tbest: 0.2168065 (7369)\ttotal: 6m 59s\tremaining: 2m 12s\n",
      "7700:\tlearn: 0.1578689\ttest: 0.2168268\tbest: 0.2168065 (7369)\ttotal: 7m 4s\tremaining: 2m 6s\n",
      "7800:\tlearn: 0.1572363\ttest: 0.2168390\tbest: 0.2168065 (7369)\ttotal: 7m 10s\tremaining: 2m 1s\n",
      "7900:\tlearn: 0.1566416\ttest: 0.2168371\tbest: 0.2168065 (7369)\ttotal: 7m 15s\tremaining: 1m 55s\n",
      "8000:\tlearn: 0.1560450\ttest: 0.2168279\tbest: 0.2168065 (7369)\ttotal: 7m 21s\tremaining: 1m 50s\n",
      "8100:\tlearn: 0.1554666\ttest: 0.2168444\tbest: 0.2168065 (7369)\ttotal: 7m 26s\tremaining: 1m 44s\n",
      "8200:\tlearn: 0.1548594\ttest: 0.2168885\tbest: 0.2168065 (7369)\ttotal: 7m 32s\tremaining: 1m 39s\n",
      "8300:\tlearn: 0.1542982\ttest: 0.2168769\tbest: 0.2168065 (7369)\ttotal: 7m 37s\tremaining: 1m 33s\n",
      "8400:\tlearn: 0.1536863\ttest: 0.2168696\tbest: 0.2168065 (7369)\ttotal: 7m 43s\tremaining: 1m 28s\n",
      "8500:\tlearn: 0.1530920\ttest: 0.2168487\tbest: 0.2168065 (7369)\ttotal: 7m 48s\tremaining: 1m 22s\n",
      "8600:\tlearn: 0.1524916\ttest: 0.2168603\tbest: 0.2168065 (7369)\ttotal: 7m 54s\tremaining: 1m 17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8700:\tlearn: 0.1518852\ttest: 0.2168445\tbest: 0.2168065 (7369)\ttotal: 8m\tremaining: 1m 11s\n",
      "8800:\tlearn: 0.1512948\ttest: 0.2168285\tbest: 0.2168065 (7369)\ttotal: 8m 5s\tremaining: 1m 6s\n",
      "8900:\tlearn: 0.1507655\ttest: 0.2168347\tbest: 0.2168065 (7369)\ttotal: 8m 11s\tremaining: 1m\n",
      "9000:\tlearn: 0.1501981\ttest: 0.2168407\tbest: 0.2168065 (7369)\ttotal: 8m 16s\tremaining: 55.1s\n",
      "9100:\tlearn: 0.1496293\ttest: 0.2168378\tbest: 0.2168065 (7369)\ttotal: 8m 22s\tremaining: 49.6s\n",
      "9200:\tlearn: 0.1490624\ttest: 0.2168519\tbest: 0.2168065 (7369)\ttotal: 8m 28s\tremaining: 44.1s\n",
      "9300:\tlearn: 0.1484923\ttest: 0.2168468\tbest: 0.2168065 (7369)\ttotal: 8m 33s\tremaining: 38.6s\n",
      "9400:\tlearn: 0.1479641\ttest: 0.2168423\tbest: 0.2168065 (7369)\ttotal: 8m 39s\tremaining: 33.1s\n",
      "9500:\tlearn: 0.1474124\ttest: 0.2168523\tbest: 0.2168065 (7369)\ttotal: 8m 44s\tremaining: 27.6s\n",
      "9600:\tlearn: 0.1468678\ttest: 0.2168690\tbest: 0.2168065 (7369)\ttotal: 8m 50s\tremaining: 22s\n",
      "9700:\tlearn: 0.1463401\ttest: 0.2168954\tbest: 0.2168065 (7369)\ttotal: 8m 55s\tremaining: 16.5s\n",
      "9800:\tlearn: 0.1458111\ttest: 0.2169010\tbest: 0.2168065 (7369)\ttotal: 9m 1s\tremaining: 11s\n",
      "9900:\tlearn: 0.1452613\ttest: 0.2169043\tbest: 0.2168065 (7369)\ttotal: 9m 7s\tremaining: 5.47s\n",
      "9999:\tlearn: 0.1447163\ttest: 0.2169294\tbest: 0.2168065 (7369)\ttotal: 9m 12s\tremaining: 0us\n",
      "bestTest = 0.2168064722\n",
      "bestIteration = 7369\n",
      "Shrink model to first 7370 iterations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2add3f94110545e3aaf83d10b6e2d238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our fold 2 CV score is 0.7948414342584729\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 2356 features...\n",
      "0:\tlearn: 0.6559801\ttest: 0.6561131\tbest: 0.6561131 (0)\ttotal: 272ms\tremaining: 45m 19s\n",
      "100:\tlearn: 0.2393968\ttest: 0.2426858\tbest: 0.2426858 (100)\ttotal: 6.34s\tremaining: 10m 21s\n",
      "200:\tlearn: 0.2277490\ttest: 0.2321627\tbest: 0.2321627 (200)\ttotal: 12.2s\tremaining: 9m 55s\n",
      "300:\tlearn: 0.2228136\ttest: 0.2281034\tbest: 0.2281034 (300)\ttotal: 17.9s\tremaining: 9m 36s\n",
      "400:\tlearn: 0.2196474\ttest: 0.2258491\tbest: 0.2258491 (400)\ttotal: 23.8s\tremaining: 9m 29s\n",
      "500:\tlearn: 0.2172825\ttest: 0.2244233\tbest: 0.2244233 (500)\ttotal: 29.6s\tremaining: 9m 21s\n",
      "600:\tlearn: 0.2152328\ttest: 0.2234363\tbest: 0.2234363 (600)\ttotal: 35.4s\tremaining: 9m 13s\n",
      "700:\tlearn: 0.2135565\ttest: 0.2227466\tbest: 0.2227466 (700)\ttotal: 41.1s\tremaining: 9m 5s\n",
      "800:\tlearn: 0.2120187\ttest: 0.2222172\tbest: 0.2222172 (800)\ttotal: 46.8s\tremaining: 8m 57s\n",
      "900:\tlearn: 0.2106431\ttest: 0.2218288\tbest: 0.2218288 (900)\ttotal: 52.5s\tremaining: 8m 49s\n",
      "1000:\tlearn: 0.2093428\ttest: 0.2214444\tbest: 0.2214444 (1000)\ttotal: 58s\tremaining: 8m 41s\n",
      "1100:\tlearn: 0.2080873\ttest: 0.2211294\tbest: 0.2211294 (1100)\ttotal: 1m 3s\tremaining: 8m 33s\n",
      "1200:\tlearn: 0.2069618\ttest: 0.2208770\tbest: 0.2208770 (1200)\ttotal: 1m 9s\tremaining: 8m 26s\n",
      "1300:\tlearn: 0.2058561\ttest: 0.2206393\tbest: 0.2206393 (1300)\ttotal: 1m 14s\tremaining: 8m 19s\n",
      "1400:\tlearn: 0.2047595\ttest: 0.2204310\tbest: 0.2204310 (1400)\ttotal: 1m 20s\tremaining: 8m 12s\n",
      "1500:\tlearn: 0.2036879\ttest: 0.2202668\tbest: 0.2202668 (1500)\ttotal: 1m 25s\tremaining: 8m 6s\n",
      "1600:\tlearn: 0.2026858\ttest: 0.2201131\tbest: 0.2201131 (1600)\ttotal: 1m 31s\tremaining: 7m 59s\n",
      "1700:\tlearn: 0.2016677\ttest: 0.2199660\tbest: 0.2199660 (1700)\ttotal: 1m 36s\tremaining: 7m 52s\n",
      "1800:\tlearn: 0.2006950\ttest: 0.2198186\tbest: 0.2198179 (1797)\ttotal: 1m 42s\tremaining: 7m 46s\n",
      "1900:\tlearn: 0.1997551\ttest: 0.2196930\tbest: 0.2196930 (1900)\ttotal: 1m 47s\tremaining: 7m 40s\n",
      "2000:\tlearn: 0.1988293\ttest: 0.2195635\tbest: 0.2195626 (1999)\ttotal: 1m 53s\tremaining: 7m 33s\n",
      "2100:\tlearn: 0.1979313\ttest: 0.2194704\tbest: 0.2194685 (2091)\ttotal: 1m 58s\tremaining: 7m 27s\n",
      "2200:\tlearn: 0.1970116\ttest: 0.2193915\tbest: 0.2193913 (2199)\ttotal: 2m 4s\tremaining: 7m 20s\n",
      "2300:\tlearn: 0.1961176\ttest: 0.2192800\tbest: 0.2192800 (2300)\ttotal: 2m 9s\tremaining: 7m 14s\n",
      "2400:\tlearn: 0.1952461\ttest: 0.2191985\tbest: 0.2191978 (2399)\ttotal: 2m 15s\tremaining: 7m 8s\n",
      "2500:\tlearn: 0.1943621\ttest: 0.2190987\tbest: 0.2190987 (2500)\ttotal: 2m 20s\tremaining: 7m 1s\n",
      "2600:\tlearn: 0.1935169\ttest: 0.2189927\tbest: 0.2189900 (2598)\ttotal: 2m 26s\tremaining: 6m 55s\n",
      "2700:\tlearn: 0.1926505\ttest: 0.2188717\tbest: 0.2188717 (2700)\ttotal: 2m 31s\tremaining: 6m 50s\n",
      "2800:\tlearn: 0.1917960\ttest: 0.2187919\tbest: 0.2187805 (2784)\ttotal: 2m 37s\tremaining: 6m 44s\n",
      "2900:\tlearn: 0.1909724\ttest: 0.2187132\tbest: 0.2187132 (2900)\ttotal: 2m 42s\tremaining: 6m 38s\n",
      "3000:\tlearn: 0.1901380\ttest: 0.2186747\tbest: 0.2186731 (2993)\ttotal: 2m 48s\tremaining: 6m 32s\n",
      "3100:\tlearn: 0.1893081\ttest: 0.2185896\tbest: 0.2185896 (3100)\ttotal: 2m 53s\tremaining: 6m 26s\n",
      "3200:\tlearn: 0.1884535\ttest: 0.2185543\tbest: 0.2185541 (3194)\ttotal: 2m 59s\tremaining: 6m 21s\n",
      "3300:\tlearn: 0.1876870\ttest: 0.2185247\tbest: 0.2185243 (3298)\ttotal: 3m 5s\tremaining: 6m 15s\n",
      "3400:\tlearn: 0.1868739\ttest: 0.2185004\tbest: 0.2184870 (3352)\ttotal: 3m 10s\tremaining: 6m 10s\n",
      "3500:\tlearn: 0.1860987\ttest: 0.2184396\tbest: 0.2184361 (3497)\ttotal: 3m 16s\tremaining: 6m 4s\n",
      "3600:\tlearn: 0.1853185\ttest: 0.2184235\tbest: 0.2184235 (3600)\ttotal: 3m 21s\tremaining: 5m 58s\n",
      "3700:\tlearn: 0.1845559\ttest: 0.2183854\tbest: 0.2183854 (3700)\ttotal: 3m 27s\tremaining: 5m 53s\n",
      "3800:\tlearn: 0.1837834\ttest: 0.2183209\tbest: 0.2183208 (3799)\ttotal: 3m 33s\tremaining: 5m 47s\n",
      "3900:\tlearn: 0.1830005\ttest: 0.2182821\tbest: 0.2182808 (3895)\ttotal: 3m 38s\tremaining: 5m 41s\n",
      "4000:\tlearn: 0.1822383\ttest: 0.2182708\tbest: 0.2182657 (3997)\ttotal: 3m 43s\tremaining: 5m 35s\n",
      "4100:\tlearn: 0.1814910\ttest: 0.2182272\tbest: 0.2182209 (4077)\ttotal: 3m 49s\tremaining: 5m 29s\n",
      "4200:\tlearn: 0.1807814\ttest: 0.2181843\tbest: 0.2181843 (4200)\ttotal: 3m 54s\tremaining: 5m 24s\n",
      "4300:\tlearn: 0.1800095\ttest: 0.2181725\tbest: 0.2181725 (4300)\ttotal: 4m\tremaining: 5m 18s\n",
      "4400:\tlearn: 0.1792861\ttest: 0.2181341\tbest: 0.2181276 (4390)\ttotal: 4m 5s\tremaining: 5m 12s\n",
      "4500:\tlearn: 0.1785360\ttest: 0.2180973\tbest: 0.2180969 (4499)\ttotal: 4m 11s\tremaining: 5m 7s\n",
      "4600:\tlearn: 0.1777831\ttest: 0.2180940\tbest: 0.2180880 (4569)\ttotal: 4m 17s\tremaining: 5m 1s\n",
      "4700:\tlearn: 0.1770693\ttest: 0.2180439\tbest: 0.2180439 (4700)\ttotal: 4m 22s\tremaining: 4m 56s\n",
      "4800:\tlearn: 0.1763446\ttest: 0.2180371\tbest: 0.2180235 (4783)\ttotal: 4m 28s\tremaining: 4m 50s\n",
      "4900:\tlearn: 0.1756401\ttest: 0.2180173\tbest: 0.2180173 (4900)\ttotal: 4m 33s\tremaining: 4m 44s\n",
      "5000:\tlearn: 0.1749170\ttest: 0.2179924\tbest: 0.2179853 (4966)\ttotal: 4m 39s\tremaining: 4m 39s\n",
      "5100:\tlearn: 0.1742248\ttest: 0.2179528\tbest: 0.2179528 (5100)\ttotal: 4m 44s\tremaining: 4m 33s\n",
      "5200:\tlearn: 0.1735027\ttest: 0.2179191\tbest: 0.2179169 (5198)\ttotal: 4m 50s\tremaining: 4m 28s\n",
      "5300:\tlearn: 0.1728251\ttest: 0.2178874\tbest: 0.2178811 (5293)\ttotal: 4m 56s\tremaining: 4m 22s\n",
      "5400:\tlearn: 0.1721274\ttest: 0.2178652\tbest: 0.2178644 (5379)\ttotal: 5m 1s\tremaining: 4m 16s\n",
      "5500:\tlearn: 0.1714492\ttest: 0.2178384\tbest: 0.2178384 (5500)\ttotal: 5m 7s\tremaining: 4m 11s\n",
      "5600:\tlearn: 0.1707534\ttest: 0.2178123\tbest: 0.2178100 (5596)\ttotal: 5m 12s\tremaining: 4m 5s\n",
      "5700:\tlearn: 0.1700478\ttest: 0.2178111\tbest: 0.2178029 (5613)\ttotal: 5m 18s\tremaining: 4m\n",
      "5800:\tlearn: 0.1694118\ttest: 0.2178123\tbest: 0.2178007 (5718)\ttotal: 5m 23s\tremaining: 3m 54s\n",
      "5900:\tlearn: 0.1687688\ttest: 0.2178038\tbest: 0.2178007 (5718)\ttotal: 5m 29s\tremaining: 3m 48s\n",
      "6000:\tlearn: 0.1680799\ttest: 0.2177918\tbest: 0.2177833 (5991)\ttotal: 5m 35s\tremaining: 3m 43s\n",
      "6100:\tlearn: 0.1674102\ttest: 0.2177879\tbest: 0.2177729 (6037)\ttotal: 5m 40s\tremaining: 3m 37s\n",
      "6200:\tlearn: 0.1668041\ttest: 0.2177759\tbest: 0.2177666 (6133)\ttotal: 5m 46s\tremaining: 3m 32s\n",
      "6300:\tlearn: 0.1661478\ttest: 0.2177553\tbest: 0.2177528 (6296)\ttotal: 5m 51s\tremaining: 3m 26s\n",
      "6400:\tlearn: 0.1655017\ttest: 0.2177506\tbest: 0.2177391 (6325)\ttotal: 5m 57s\tremaining: 3m 20s\n",
      "6500:\tlearn: 0.1648440\ttest: 0.2177512\tbest: 0.2177391 (6325)\ttotal: 6m 2s\tremaining: 3m 15s\n",
      "6600:\tlearn: 0.1642098\ttest: 0.2177589\tbest: 0.2177391 (6325)\ttotal: 6m 8s\tremaining: 3m 9s\n",
      "6700:\tlearn: 0.1635555\ttest: 0.2177638\tbest: 0.2177391 (6325)\ttotal: 6m 14s\tremaining: 3m 4s\n",
      "6800:\tlearn: 0.1629267\ttest: 0.2177591\tbest: 0.2177391 (6325)\ttotal: 6m 19s\tremaining: 2m 58s\n",
      "6900:\tlearn: 0.1623058\ttest: 0.2177404\tbest: 0.2177382 (6899)\ttotal: 6m 25s\tremaining: 2m 52s\n",
      "7000:\tlearn: 0.1616890\ttest: 0.2177195\tbest: 0.2177163 (6993)\ttotal: 6m 30s\tremaining: 2m 47s\n",
      "7100:\tlearn: 0.1610486\ttest: 0.2177040\tbest: 0.2177028 (7099)\ttotal: 6m 36s\tremaining: 2m 41s\n",
      "7200:\tlearn: 0.1604421\ttest: 0.2176883\tbest: 0.2176846 (7144)\ttotal: 6m 41s\tremaining: 2m 36s\n",
      "7300:\tlearn: 0.1598163\ttest: 0.2177124\tbest: 0.2176846 (7144)\ttotal: 6m 47s\tremaining: 2m 30s\n",
      "7400:\tlearn: 0.1592056\ttest: 0.2177078\tbest: 0.2176846 (7144)\ttotal: 6m 53s\tremaining: 2m 25s\n",
      "7500:\tlearn: 0.1586070\ttest: 0.2176854\tbest: 0.2176828 (7491)\ttotal: 6m 58s\tremaining: 2m 19s\n",
      "7600:\tlearn: 0.1579860\ttest: 0.2176695\tbest: 0.2176695 (7600)\ttotal: 7m 4s\tremaining: 2m 13s\n",
      "7700:\tlearn: 0.1573713\ttest: 0.2176695\tbest: 0.2176493 (7651)\ttotal: 7m 9s\tremaining: 2m 8s\n",
      "7800:\tlearn: 0.1567663\ttest: 0.2176599\tbest: 0.2176493 (7651)\ttotal: 7m 15s\tremaining: 2m 2s\n",
      "7900:\tlearn: 0.1561561\ttest: 0.2176462\tbest: 0.2176402 (7843)\ttotal: 7m 20s\tremaining: 1m 57s\n",
      "8000:\tlearn: 0.1555688\ttest: 0.2176497\tbest: 0.2176381 (7952)\ttotal: 7m 26s\tremaining: 1m 51s\n",
      "8100:\tlearn: 0.1549512\ttest: 0.2176448\tbest: 0.2176381 (7952)\ttotal: 7m 31s\tremaining: 1m 45s\n",
      "8200:\tlearn: 0.1543538\ttest: 0.2176728\tbest: 0.2176381 (7952)\ttotal: 7m 37s\tremaining: 1m 40s\n",
      "8300:\tlearn: 0.1537341\ttest: 0.2176647\tbest: 0.2176381 (7952)\ttotal: 7m 42s\tremaining: 1m 34s\n",
      "8400:\tlearn: 0.1531494\ttest: 0.2176522\tbest: 0.2176381 (7952)\ttotal: 7m 48s\tremaining: 1m 29s\n",
      "8500:\tlearn: 0.1525836\ttest: 0.2176453\tbest: 0.2176381 (7952)\ttotal: 7m 53s\tremaining: 1m 23s\n",
      "8600:\tlearn: 0.1519961\ttest: 0.2176527\tbest: 0.2176381 (7952)\ttotal: 7m 59s\tremaining: 1m 17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8700:\tlearn: 0.1514151\ttest: 0.2176491\tbest: 0.2176381 (7952)\ttotal: 8m 4s\tremaining: 1m 12s\n",
      "8800:\tlearn: 0.1508292\ttest: 0.2176455\tbest: 0.2176381 (7952)\ttotal: 8m 10s\tremaining: 1m 6s\n",
      "8900:\tlearn: 0.1502247\ttest: 0.2176423\tbest: 0.2176381 (7952)\ttotal: 8m 15s\tremaining: 1m 1s\n",
      "9000:\tlearn: 0.1496661\ttest: 0.2176525\tbest: 0.2176381 (7952)\ttotal: 8m 21s\tremaining: 55.6s\n",
      "9100:\tlearn: 0.1491065\ttest: 0.2176774\tbest: 0.2176381 (7952)\ttotal: 8m 26s\tremaining: 50s\n",
      "9200:\tlearn: 0.1485727\ttest: 0.2176849\tbest: 0.2176381 (7952)\ttotal: 8m 32s\tremaining: 44.5s\n",
      "9300:\tlearn: 0.1480186\ttest: 0.2176888\tbest: 0.2176381 (7952)\ttotal: 8m 37s\tremaining: 38.9s\n",
      "9400:\tlearn: 0.1474430\ttest: 0.2176680\tbest: 0.2176381 (7952)\ttotal: 8m 43s\tremaining: 33.3s\n",
      "9500:\tlearn: 0.1468976\ttest: 0.2176784\tbest: 0.2176381 (7952)\ttotal: 8m 48s\tremaining: 27.8s\n",
      "9600:\tlearn: 0.1463346\ttest: 0.2177012\tbest: 0.2176381 (7952)\ttotal: 8m 54s\tremaining: 22.2s\n",
      "9700:\tlearn: 0.1457706\ttest: 0.2176830\tbest: 0.2176381 (7952)\ttotal: 8m 59s\tremaining: 16.6s\n",
      "9800:\tlearn: 0.1452499\ttest: 0.2176743\tbest: 0.2176381 (7952)\ttotal: 9m 5s\tremaining: 11.1s\n",
      "9900:\tlearn: 0.1447255\ttest: 0.2177040\tbest: 0.2176381 (7952)\ttotal: 9m 10s\tremaining: 5.51s\n",
      "9999:\tlearn: 0.1441719\ttest: 0.2177098\tbest: 0.2176381 (7952)\ttotal: 9m 16s\tremaining: 0us\n",
      "bestTest = 0.2176380751\n",
      "bestIteration = 7952\n",
      "Shrink model to first 7953 iterations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291aa1423af9456f971c25bff22d4c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our fold 3 CV score is 0.7931036149203536\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 2356 features...\n",
      "0:\tlearn: 0.6561225\ttest: 0.6561543\tbest: 0.6561543 (0)\ttotal: 313ms\tremaining: 52m 12s\n",
      "100:\tlearn: 0.2401478\ttest: 0.2401986\tbest: 0.2401986 (100)\ttotal: 6.14s\tremaining: 10m 2s\n",
      "200:\tlearn: 0.2284808\ttest: 0.2291907\tbest: 0.2291907 (200)\ttotal: 12s\tremaining: 9m 43s\n",
      "300:\tlearn: 0.2236734\ttest: 0.2251445\tbest: 0.2251445 (300)\ttotal: 17.7s\tremaining: 9m 30s\n",
      "400:\tlearn: 0.2205221\ttest: 0.2229195\tbest: 0.2229195 (400)\ttotal: 23.4s\tremaining: 9m 20s\n",
      "500:\tlearn: 0.2180981\ttest: 0.2214304\tbest: 0.2214304 (500)\ttotal: 29.1s\tremaining: 9m 11s\n",
      "600:\tlearn: 0.2160736\ttest: 0.2204101\tbest: 0.2204101 (600)\ttotal: 34.9s\tremaining: 9m 5s\n",
      "700:\tlearn: 0.2143819\ttest: 0.2196940\tbest: 0.2196940 (700)\ttotal: 40.4s\tremaining: 8m 56s\n",
      "800:\tlearn: 0.2129014\ttest: 0.2191436\tbest: 0.2191436 (800)\ttotal: 45.9s\tremaining: 8m 47s\n",
      "900:\tlearn: 0.2114735\ttest: 0.2186348\tbest: 0.2186348 (900)\ttotal: 51.5s\tremaining: 8m 39s\n",
      "1000:\tlearn: 0.2101696\ttest: 0.2182671\tbest: 0.2182666 (999)\ttotal: 57.1s\tremaining: 8m 33s\n",
      "1100:\tlearn: 0.2089476\ttest: 0.2179376\tbest: 0.2179376 (1100)\ttotal: 1m 2s\tremaining: 8m 26s\n",
      "1200:\tlearn: 0.2078352\ttest: 0.2176479\tbest: 0.2176479 (1200)\ttotal: 1m 8s\tremaining: 8m 21s\n",
      "1300:\tlearn: 0.2067337\ttest: 0.2174749\tbest: 0.2174749 (1300)\ttotal: 1m 14s\tremaining: 8m 15s\n",
      "1400:\tlearn: 0.2056537\ttest: 0.2173008\tbest: 0.2173008 (1400)\ttotal: 1m 19s\tremaining: 8m 9s\n",
      "1500:\tlearn: 0.2045761\ttest: 0.2170973\tbest: 0.2170973 (1500)\ttotal: 1m 25s\tremaining: 8m 3s\n",
      "1600:\tlearn: 0.2035668\ttest: 0.2169306\tbest: 0.2169306 (1600)\ttotal: 1m 31s\tremaining: 7m 57s\n",
      "1700:\tlearn: 0.2025815\ttest: 0.2167726\tbest: 0.2167717 (1699)\ttotal: 1m 36s\tremaining: 7m 50s\n",
      "1800:\tlearn: 0.2016168\ttest: 0.2166702\tbest: 0.2166702 (1800)\ttotal: 1m 42s\tremaining: 7m 45s\n",
      "1900:\tlearn: 0.2006790\ttest: 0.2165349\tbest: 0.2165349 (1899)\ttotal: 1m 47s\tremaining: 7m 39s\n",
      "2000:\tlearn: 0.1997409\ttest: 0.2164149\tbest: 0.2164135 (1999)\ttotal: 1m 53s\tremaining: 7m 33s\n",
      "2100:\tlearn: 0.1988155\ttest: 0.2163071\tbest: 0.2163061 (2094)\ttotal: 1m 59s\tremaining: 7m 27s\n",
      "2200:\tlearn: 0.1979223\ttest: 0.2162203\tbest: 0.2162201 (2195)\ttotal: 2m 4s\tremaining: 7m 21s\n",
      "2300:\tlearn: 0.1970386\ttest: 0.2161145\tbest: 0.2161128 (2299)\ttotal: 2m 10s\tremaining: 7m 16s\n",
      "2400:\tlearn: 0.1961542\ttest: 0.2160310\tbest: 0.2160303 (2399)\ttotal: 2m 15s\tremaining: 7m 10s\n",
      "2500:\tlearn: 0.1953203\ttest: 0.2159484\tbest: 0.2159476 (2487)\ttotal: 2m 21s\tremaining: 7m 4s\n",
      "2600:\tlearn: 0.1944639\ttest: 0.2159002\tbest: 0.2158994 (2598)\ttotal: 2m 27s\tremaining: 6m 58s\n",
      "2700:\tlearn: 0.1936450\ttest: 0.2158275\tbest: 0.2158275 (2700)\ttotal: 2m 32s\tremaining: 6m 52s\n",
      "2800:\tlearn: 0.1928034\ttest: 0.2157808\tbest: 0.2157808 (2790)\ttotal: 2m 38s\tremaining: 6m 47s\n",
      "2900:\tlearn: 0.1919941\ttest: 0.2157200\tbest: 0.2157150 (2894)\ttotal: 2m 44s\tremaining: 6m 41s\n",
      "3000:\tlearn: 0.1911957\ttest: 0.2156541\tbest: 0.2156541 (3000)\ttotal: 2m 49s\tremaining: 6m 35s\n",
      "3100:\tlearn: 0.1903803\ttest: 0.2155556\tbest: 0.2155552 (3099)\ttotal: 2m 55s\tremaining: 6m 29s\n",
      "3200:\tlearn: 0.1895537\ttest: 0.2154999\tbest: 0.2154994 (3198)\ttotal: 3m\tremaining: 6m 24s\n",
      "3300:\tlearn: 0.1887397\ttest: 0.2154572\tbest: 0.2154572 (3300)\ttotal: 3m 6s\tremaining: 6m 18s\n",
      "3400:\tlearn: 0.1879561\ttest: 0.2154149\tbest: 0.2154068 (3387)\ttotal: 3m 11s\tremaining: 6m 12s\n",
      "3500:\tlearn: 0.1871436\ttest: 0.2153678\tbest: 0.2153678 (3500)\ttotal: 3m 17s\tremaining: 6m 6s\n",
      "3600:\tlearn: 0.1863321\ttest: 0.2153199\tbest: 0.2153134 (3594)\ttotal: 3m 23s\tremaining: 6m\n",
      "3700:\tlearn: 0.1855489\ttest: 0.2152806\tbest: 0.2152802 (3699)\ttotal: 3m 28s\tremaining: 5m 55s\n",
      "3800:\tlearn: 0.1847736\ttest: 0.2152369\tbest: 0.2152369 (3800)\ttotal: 3m 34s\tremaining: 5m 49s\n",
      "3900:\tlearn: 0.1840161\ttest: 0.2151906\tbest: 0.2151893 (3899)\ttotal: 3m 39s\tremaining: 5m 43s\n",
      "4000:\tlearn: 0.1832840\ttest: 0.2151654\tbest: 0.2151638 (3982)\ttotal: 3m 45s\tremaining: 5m 38s\n",
      "4100:\tlearn: 0.1825109\ttest: 0.2151153\tbest: 0.2151129 (4097)\ttotal: 3m 51s\tremaining: 5m 32s\n",
      "4200:\tlearn: 0.1817488\ttest: 0.2150258\tbest: 0.2150258 (4200)\ttotal: 3m 56s\tremaining: 5m 26s\n",
      "4300:\tlearn: 0.1810204\ttest: 0.2150054\tbest: 0.2149972 (4278)\ttotal: 4m 2s\tremaining: 5m 21s\n",
      "4400:\tlearn: 0.1802985\ttest: 0.2149805\tbest: 0.2149773 (4386)\ttotal: 4m 7s\tremaining: 5m 15s\n",
      "4500:\tlearn: 0.1795647\ttest: 0.2149494\tbest: 0.2149494 (4500)\ttotal: 4m 13s\tremaining: 5m 9s\n",
      "4600:\tlearn: 0.1788296\ttest: 0.2149503\tbest: 0.2149346 (4562)\ttotal: 4m 19s\tremaining: 5m 4s\n",
      "4700:\tlearn: 0.1780922\ttest: 0.2149145\tbest: 0.2149082 (4696)\ttotal: 4m 24s\tremaining: 4m 58s\n",
      "4800:\tlearn: 0.1773916\ttest: 0.2148885\tbest: 0.2148820 (4779)\ttotal: 4m 30s\tremaining: 4m 52s\n",
      "4900:\tlearn: 0.1766776\ttest: 0.2148726\tbest: 0.2148644 (4868)\ttotal: 4m 35s\tremaining: 4m 47s\n",
      "5000:\tlearn: 0.1759486\ttest: 0.2148659\tbest: 0.2148644 (4868)\ttotal: 4m 41s\tremaining: 4m 41s\n",
      "5100:\tlearn: 0.1752591\ttest: 0.2148452\tbest: 0.2148394 (5091)\ttotal: 4m 46s\tremaining: 4m 35s\n",
      "5200:\tlearn: 0.1745166\ttest: 0.2148151\tbest: 0.2148151 (5200)\ttotal: 4m 52s\tremaining: 4m 29s\n",
      "5300:\tlearn: 0.1738089\ttest: 0.2148052\tbest: 0.2147991 (5285)\ttotal: 4m 58s\tremaining: 4m 24s\n",
      "5400:\tlearn: 0.1731182\ttest: 0.2147882\tbest: 0.2147798 (5341)\ttotal: 5m 3s\tremaining: 4m 18s\n",
      "5500:\tlearn: 0.1724192\ttest: 0.2147760\tbest: 0.2147723 (5478)\ttotal: 5m 9s\tremaining: 4m 12s\n",
      "5600:\tlearn: 0.1717318\ttest: 0.2147830\tbest: 0.2147591 (5567)\ttotal: 5m 14s\tremaining: 4m 7s\n",
      "5700:\tlearn: 0.1710700\ttest: 0.2148188\tbest: 0.2147591 (5567)\ttotal: 5m 20s\tremaining: 4m 1s\n",
      "5800:\tlearn: 0.1704097\ttest: 0.2148200\tbest: 0.2147591 (5567)\ttotal: 5m 25s\tremaining: 3m 55s\n",
      "5900:\tlearn: 0.1697600\ttest: 0.2148127\tbest: 0.2147591 (5567)\ttotal: 5m 31s\tremaining: 3m 49s\n",
      "6000:\tlearn: 0.1690997\ttest: 0.2148065\tbest: 0.2147591 (5567)\ttotal: 5m 36s\tremaining: 3m 44s\n",
      "6100:\tlearn: 0.1684520\ttest: 0.2147934\tbest: 0.2147591 (5567)\ttotal: 5m 41s\tremaining: 3m 38s\n",
      "6200:\tlearn: 0.1677840\ttest: 0.2147846\tbest: 0.2147591 (5567)\ttotal: 5m 47s\tremaining: 3m 32s\n",
      "6300:\tlearn: 0.1670991\ttest: 0.2147791\tbest: 0.2147591 (5567)\ttotal: 5m 53s\tremaining: 3m 27s\n",
      "6400:\tlearn: 0.1664496\ttest: 0.2148100\tbest: 0.2147591 (5567)\ttotal: 5m 58s\tremaining: 3m 21s\n",
      "6500:\tlearn: 0.1658269\ttest: 0.2147853\tbest: 0.2147591 (5567)\ttotal: 6m 4s\tremaining: 3m 15s\n",
      "6600:\tlearn: 0.1652138\ttest: 0.2148066\tbest: 0.2147591 (5567)\ttotal: 6m 9s\tremaining: 3m 10s\n",
      "6700:\tlearn: 0.1645683\ttest: 0.2148104\tbest: 0.2147591 (5567)\ttotal: 6m 15s\tremaining: 3m 4s\n",
      "6800:\tlearn: 0.1639220\ttest: 0.2148190\tbest: 0.2147591 (5567)\ttotal: 6m 20s\tremaining: 2m 59s\n",
      "6900:\tlearn: 0.1633004\ttest: 0.2148372\tbest: 0.2147591 (5567)\ttotal: 6m 26s\tremaining: 2m 53s\n",
      "7000:\tlearn: 0.1627211\ttest: 0.2148205\tbest: 0.2147591 (5567)\ttotal: 6m 32s\tremaining: 2m 48s\n",
      "7100:\tlearn: 0.1620985\ttest: 0.2148678\tbest: 0.2147591 (5567)\ttotal: 6m 37s\tremaining: 2m 42s\n",
      "7200:\tlearn: 0.1614331\ttest: 0.2148460\tbest: 0.2147591 (5567)\ttotal: 6m 43s\tremaining: 2m 36s\n",
      "7300:\tlearn: 0.1608193\ttest: 0.2148321\tbest: 0.2147591 (5567)\ttotal: 6m 49s\tremaining: 2m 31s\n",
      "7400:\tlearn: 0.1601923\ttest: 0.2148224\tbest: 0.2147591 (5567)\ttotal: 6m 54s\tremaining: 2m 25s\n",
      "7500:\tlearn: 0.1595681\ttest: 0.2148240\tbest: 0.2147591 (5567)\ttotal: 7m\tremaining: 2m 20s\n",
      "7600:\tlearn: 0.1589536\ttest: 0.2148137\tbest: 0.2147591 (5567)\ttotal: 7m 6s\tremaining: 2m 14s\n",
      "7700:\tlearn: 0.1583528\ttest: 0.2148056\tbest: 0.2147591 (5567)\ttotal: 7m 12s\tremaining: 2m 9s\n",
      "7800:\tlearn: 0.1577357\ttest: 0.2148385\tbest: 0.2147591 (5567)\ttotal: 7m 17s\tremaining: 2m 3s\n",
      "7900:\tlearn: 0.1571213\ttest: 0.2148266\tbest: 0.2147591 (5567)\ttotal: 7m 23s\tremaining: 1m 57s\n",
      "8000:\tlearn: 0.1565374\ttest: 0.2148379\tbest: 0.2147591 (5567)\ttotal: 7m 29s\tremaining: 1m 52s\n",
      "8100:\tlearn: 0.1559737\ttest: 0.2148205\tbest: 0.2147591 (5567)\ttotal: 7m 34s\tremaining: 1m 46s\n",
      "8200:\tlearn: 0.1553851\ttest: 0.2148170\tbest: 0.2147591 (5567)\ttotal: 7m 40s\tremaining: 1m 40s\n",
      "8300:\tlearn: 0.1547687\ttest: 0.2148405\tbest: 0.2147591 (5567)\ttotal: 7m 45s\tremaining: 1m 35s\n",
      "8400:\tlearn: 0.1541850\ttest: 0.2148336\tbest: 0.2147591 (5567)\ttotal: 7m 51s\tremaining: 1m 29s\n",
      "8500:\tlearn: 0.1535964\ttest: 0.2148411\tbest: 0.2147591 (5567)\ttotal: 7m 57s\tremaining: 1m 24s\n",
      "8600:\tlearn: 0.1530361\ttest: 0.2148424\tbest: 0.2147591 (5567)\ttotal: 8m 2s\tremaining: 1m 18s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8700:\tlearn: 0.1524686\ttest: 0.2148384\tbest: 0.2147591 (5567)\ttotal: 8m 8s\tremaining: 1m 12s\n",
      "8800:\tlearn: 0.1519016\ttest: 0.2148650\tbest: 0.2147591 (5567)\ttotal: 8m 13s\tremaining: 1m 7s\n",
      "8900:\tlearn: 0.1513254\ttest: 0.2148812\tbest: 0.2147591 (5567)\ttotal: 8m 19s\tremaining: 1m 1s\n",
      "9000:\tlearn: 0.1507707\ttest: 0.2148704\tbest: 0.2147591 (5567)\ttotal: 8m 24s\tremaining: 56s\n",
      "9100:\tlearn: 0.1502243\ttest: 0.2148820\tbest: 0.2147591 (5567)\ttotal: 8m 30s\tremaining: 50.4s\n",
      "9200:\tlearn: 0.1496639\ttest: 0.2148932\tbest: 0.2147591 (5567)\ttotal: 8m 36s\tremaining: 44.8s\n",
      "9300:\tlearn: 0.1490823\ttest: 0.2149201\tbest: 0.2147591 (5567)\ttotal: 8m 42s\tremaining: 39.2s\n",
      "9400:\tlearn: 0.1485421\ttest: 0.2149105\tbest: 0.2147591 (5567)\ttotal: 8m 47s\tremaining: 33.6s\n",
      "9500:\tlearn: 0.1479786\ttest: 0.2149286\tbest: 0.2147591 (5567)\ttotal: 8m 53s\tremaining: 28s\n",
      "9600:\tlearn: 0.1474446\ttest: 0.2149488\tbest: 0.2147591 (5567)\ttotal: 8m 58s\tremaining: 22.4s\n",
      "9700:\tlearn: 0.1468877\ttest: 0.2149543\tbest: 0.2147591 (5567)\ttotal: 9m 4s\tremaining: 16.8s\n",
      "9800:\tlearn: 0.1463038\ttest: 0.2149780\tbest: 0.2147591 (5567)\ttotal: 9m 9s\tremaining: 11.2s\n",
      "9900:\tlearn: 0.1457660\ttest: 0.2149765\tbest: 0.2147591 (5567)\ttotal: 9m 15s\tremaining: 5.55s\n",
      "9999:\tlearn: 0.1452404\ttest: 0.2149848\tbest: 0.2147591 (5567)\ttotal: 9m 21s\tremaining: 0us\n",
      "bestTest = 0.2147591193\n",
      "bestIteration = 5567\n",
      "Shrink model to first 5568 iterations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcb9f2b8eb640d8becf573e0780d1fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our fold 4 CV score is 0.7959801966825741\n",
      "Our out of folds CV score is 0.7952451818721405\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd5c534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55ad7ea2",
   "metadata": {
    "papermill": {
     "duration": 0.002942,
     "end_time": "2022-07-08T16:22:34.769748",
     "exception": false,
     "start_time": "2022-07-08T16:22:34.766806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Read Submission File\n",
    "This is the submission file corresponding to the output of the previous pipeline (using the average blend of 3 seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4707bf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T16:22:34.777872Z",
     "iopub.status.busy": "2022-07-08T16:22:34.777119Z",
     "iopub.status.idle": "2022-07-08T16:22:42.173852Z",
     "shell.execute_reply": "2022-07-08T16:22:42.172652Z"
    },
    "papermill": {
     "duration": 7.403808,
     "end_time": "2022-07-08T16:22:42.176731",
     "exception": false,
     "start_time": "2022-07-08T16:22:34.772923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sub = pd.read_csv('../input/amex-sub/test_lgbm_baseline_5fold_seed_blend.csv')\n",
    "# sub.to_csv('test_lgbm_baseline_5fold_seed_blend.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa1eebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a442960d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.185921,
   "end_time": "2022-07-08T16:22:43.001483",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-08T16:22:22.815562",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
