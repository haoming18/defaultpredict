{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2991d5a9",
   "metadata": {
    "papermill": {
     "duration": 0.002483,
     "end_time": "2022-07-08T16:22:32.606139",
     "exception": false,
     "start_time": "2022-07-08T16:22:32.603656",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e463318",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T16:22:32.613941Z",
     "iopub.status.busy": "2022-07-08T16:22:32.612882Z",
     "iopub.status.idle": "2022-07-08T16:22:32.784248Z",
     "shell.execute_reply": "2022-07-08T16:22:32.783021Z"
    },
    "papermill": {
     "duration": 0.17854,
     "end_time": "2022-07-08T16:22:32.787260",
     "exception": false,
     "start_time": "2022-07-08T16:22:32.608720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import joblib\n",
    "import random\n",
    "import warnings\n",
    "import itertools\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from itertools import combinations\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "def get_difference(data, num_features):\n",
    "    df1,df3,df6 = [],[],[]\n",
    "    customer_ids = []\n",
    "    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n",
    "        diff_df1 = df[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n",
    "        diff_df3 = df[num_features].diff(3).iloc[[-1]].values.astype(np.float32)\n",
    "        diff_df6 = df[num_features].diff(6).iloc[[-1]].values.astype(np.float32)\n",
    "\n",
    "        df1.append(diff_df1)\n",
    "        df3.append(diff_df3)\n",
    "        df6.append(diff_df6)\n",
    "        customer_ids.append(customer_id)\n",
    "        \n",
    "    df1 = np.concatenate(df1, axis = 0)\n",
    "    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n",
    "    df3 = np.concatenate(df3, axis = 0)\n",
    "    df3 = pd.DataFrame(df3, columns = [col + '_diff3' for col in df[num_features].columns])\n",
    "    df6 = np.concatenate(df6, axis = 0)\n",
    "    df6 = pd.DataFrame(df6, columns = [col + '_diff6' for col in df[num_features].columns])\n",
    "    df_all = pd.concat([df1,df3,df6],axis=1)\n",
    "    df_all['customer_ID'] = customer_ids\n",
    "    return df_all\n",
    "\n",
    "def read_preprocess_data():\n",
    "    train = pd.read_parquet('../input/amex-data-integer-dtypes-parquet-format/train.parquet')\n",
    "    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\",\n",
    "    ]\n",
    "    num_features = [col for col in features if col not in cat_features]\n",
    "    print('Starting training feature engineer...')\n",
    "    train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max'])\n",
    "    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
    "    train_num_agg.reset_index(inplace = True)\n",
    "    \n",
    "    train_tail2 = train.groupby(\"customer_ID\").tail(2)\n",
    "    train_tail2_num_agg = train_tail2.groupby(\"customer_ID\")[num_features].agg(['mean'])\n",
    "    train_tail2_num_agg.columns = ['_'.join([xx.replace('mean','last') for xx in x]) for x in train_tail2_num_agg.columns]\n",
    "    train_tail2_num_agg.reset_index(inplace = True)\n",
    "\n",
    "    train_num_agg = train_num_agg.merge(train_tail2_num_agg, how = 'inner', on = 'customer_ID')\n",
    "    # Lag Features\n",
    "    for col in num_features:\n",
    "        train_num_agg[f'{col}_last_mean_diff'] = train_num_agg[f'{col}_last'] - train_num_agg[f'{col}_mean']\n",
    "        train_num_agg[f'{col}_last_first_diff'] = train_num_agg[f'{col}_last'] - train_num_agg[f'{col}_first']\n",
    "\n",
    "    train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['count', 'first', 'last', 'nunique'])\n",
    "    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
    "    train_cat_agg.reset_index(inplace = True)\n",
    "    train_labels = pd.read_csv('../input/amex-default-prediction/train_labels.csv')\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(train_num_agg.dtypes[train_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_num_agg[col] = train_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(train_cat_agg.dtypes[train_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_cat_agg[col] = train_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    train_diff = get_difference(train, num_features)\n",
    "    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').\\\n",
    "            merge(train_diff, how = 'inner', on = 'customer_ID').\\\n",
    "            merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "    del train_num_agg, train_cat_agg, train_diff, train_tail2_num_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    test = pd.read_parquet('../input/amex-data-integer-dtypes-parquet-format/test.parquet')\n",
    "    print('Starting test feature engineer...')\n",
    "    test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "    test_num_agg.reset_index(inplace = True)\n",
    "\n",
    "    \n",
    "    test_tail2 = test.groupby(\"customer_ID\").tail(2)\n",
    "    test_tail2_num_agg = test_tail2.groupby(\"customer_ID\")[num_features].agg(['mean'])\n",
    "    test_tail2_num_agg.columns = ['_'.join([xx.replace('mean','last') for xx in x]) for x in test_tail2_num_agg.columns]\n",
    "    test_tail2_num_agg.reset_index(inplace = True)\n",
    "\n",
    "    test_num_agg = test_num_agg.merge(test_tail2_num_agg, how = 'inner', on = 'customer_ID')\n",
    "\n",
    "    # Lag Features\n",
    "    for col in num_features:\n",
    "        test_num_agg[f'{col}_last_mean_diff'] = test_num_agg[f'{col}_last'] - test_num_agg[f'{col}_mean']\n",
    "        test_num_agg[f'{col}_last_first_diff'] = test_num_agg[f'{col}_last'] - test_num_agg[f'{col}_first']\n",
    "\n",
    "\n",
    "    test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['count', 'first', 'last', 'nunique'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "    test_cat_agg.reset_index(inplace = True)\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(test_num_agg.dtypes[test_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_num_agg[col] = test_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(test_cat_agg.dtypes[test_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_cat_agg[col] = test_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    test_diff = get_difference(test, num_features)\n",
    "    test = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID').\\\n",
    "            merge(test_diff, how = 'inner', on = 'customer_ID')\n",
    "    del test_num_agg, test_cat_agg, test_diff\n",
    "    gc.collect()\n",
    "\n",
    "    features = train.drop(['customer_ID'], axis = 1).columns.to_list()\n",
    "    num_features = [col for col in features if col not in cat_features]\n",
    "    num_cols = [col for col in num_features if (('last' in col or 'mean' in col) and 'diff' not in col)]\n",
    "    for col in num_cols:\n",
    "        train[col + '_round2'] = train[col].round(2)\n",
    "        test[col + '_round2'] = test[col].round(2)\n",
    "    \n",
    "    print('train.shape:',train.shape)\n",
    "    print('test.shape:',test.shape)\n",
    "\n",
    "    # Save files to disk\n",
    "    train.to_parquet('train_fe_v2.parquet')\n",
    "    test.to_parquet('test_fe_v2.parquet')\n",
    "    \n",
    "# Read & Preprocess Data\n",
    "read_preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa1eebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a442960d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.185921,
   "end_time": "2022-07-08T16:22:43.001483",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-08T16:22:22.815562",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
